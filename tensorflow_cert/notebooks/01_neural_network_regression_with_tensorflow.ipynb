{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DBENka2HnaT3"
      },
      "source": [
        "## Intro to Regression Models with Neural Networks\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KPMRthE3oQ_d",
        "outputId": "9cb58fe8-0417-422a-8ea4-54c054901715"
      },
      "outputs": [
        {
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'tensorflow.python.tools'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[1;32m/home/synthline/codes/ml_courses/tensorflow_cert/01_neural_network_regression_with_tensorflow.ipynb Cell 2\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/synthline/codes/ml_courses/tensorflow_cert/01_neural_network_regression_with_tensorflow.ipynb#W1sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mtf\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/synthline/codes/ml_courses/tensorflow_cert/01_neural_network_regression_with_tensorflow.ipynb#W1sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mnumpy\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mnp\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/synthline/codes/ml_courses/tensorflow_cert/01_neural_network_regression_with_tensorflow.ipynb#W1sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mmatplotlib\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpyplot\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mplt\u001b[39;00m\n",
            "File \u001b[0;32m~/anaconda3/envs/iaml/lib/python3.9/site-packages/tensorflow/__init__.py:37\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39msys\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39m_sys\u001b[39;00m\n\u001b[1;32m     35\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtyping\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39m_typing\u001b[39;00m\n\u001b[0;32m---> 37\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mtools\u001b[39;00m \u001b[39mimport\u001b[39;00m module_util \u001b[39mas\u001b[39;00m _module_util\n\u001b[1;32m     38\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutil\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mlazy_loader\u001b[39;00m \u001b[39mimport\u001b[39;00m LazyLoader \u001b[39mas\u001b[39;00m _LazyLoader\n\u001b[1;32m     40\u001b[0m \u001b[39m# Make sure code inside the TensorFlow codebase can use tf2.enabled() at import.\u001b[39;00m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow.python.tools'"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "print(tf.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "yXNpj_1GoViI"
      },
      "outputs": [],
      "source": [
        "# Create data to view and fit\n",
        "\n",
        "#features\n",
        "X = np.array([-7.0, -4.0, -1.0, 2.0, 5.0, 8.0, 11.0, 14.0])\n",
        "\n",
        "# labels\n",
        "\n",
        "y = np.array([3.0, 6.0, 9.0, 12.0, 15.0, 18.0, 21.0, 24.0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        },
        "id": "tnQjPuA2ofVC",
        "outputId": "5226c320-a8ef-476c-d049-b6639b9aa825"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Visualize it\n",
        "\n",
        "plt.scatter(X, y);"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6IYixpwjpCys",
        "outputId": "1c259c1a-1f89-4486-a018-db0a50a998da"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([ True,  True,  True,  True,  True,  True,  True,  True])"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        " y == X + 10"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d8pRpspjp_jG"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1O9efSbCzIJo",
        "outputId": "cee6a50f-2e9d-4160-da1d-f85910b8e1ad"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(<tf.Tensor: shape=(8,), dtype=float64, numpy=array([-7., -4., -1.,  2.,  5.,  8., 11., 14.])>,\n",
              " <tf.Tensor: shape=(8,), dtype=float64, numpy=array([ 3.,  6.,  9., 12., 15., 18., 21., 24.])>)"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Transform into tensors\n",
        "\n",
        "X = tf.constant(X)\n",
        "y = tf.constant(y)\n",
        "X, y"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sleFTB2Y0P7t"
      },
      "source": [
        "# Steps in modelling with TF\n",
        "\n",
        "**1. Creating a model** - define the input (X) amd output layers (y), as well as the hidden layers of a deep learning model\n",
        "\n",
        "**2. Compiling the model** - define the loss function (in other words, the function which tells our model how wrong it is) and the optimizer(tells our model how to improve the patterns its learning) and evaluaton metrics (what we canuse to interpret the performance of our model).\n",
        "\n",
        "**3. Fitting the model** - letting the model try to find patterns between X and y. (feature and labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KNZD0kGI4gAb",
        "outputId": "186e7d99-6d3d-4576-ce10-0df7e1634502"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "1/1 [==============================] - 1s 904ms/step - loss: 11.5048 - mae: 11.5048\n",
            "Epoch 2/5\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 11.3723 - mae: 11.3723\n",
            "Epoch 3/5\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 11.2398 - mae: 11.2398\n",
            "Epoch 4/5\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 11.1073 - mae: 11.1073\n",
            "Epoch 5/5\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 10.9748 - mae: 10.9748\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f2eead20810>"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Set Random Seed\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "# 1.Create a  model using the Sequential API \n",
        "\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(1)\n",
        "    ])\n",
        "\n",
        "# 2. Compile the model \n",
        "model.compile(loss=tf.keras.losses.mae, #mae is short for mean absolute error\n",
        "              optimizer=tf.keras.optimizers.SGD(), #mae is short for sochastic medial descent\n",
        "              metrics=[\"mae\"]) # \"mae\" - same as writing the function tf.keras....\n",
        "\n",
        "# 3. Fit the model\n",
        "model.fit(tf.expand_dims(X, axis=-1), y, epochs=5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1VUq3Yf-4tX6",
        "outputId": "66694e26-7ce8-48d8-f34a-2d5067d6d541"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(<tf.Tensor: shape=(8,), dtype=float64, numpy=array([-7., -4., -1.,  2.,  5.,  8., 11., 14.])>,\n",
              " <tf.Tensor: shape=(8,), dtype=float64, numpy=array([ 3.,  6.,  9., 12., 15., 18., 21., 24.])>)"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Check out X and y\n",
        "\n",
        "X, y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pt-vSKfq8J4D",
        "outputId": "83cbcc45-ac30-4578-a6f7-92b0078d6c5c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 0s 197ms/step\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "array([[12.716021]], dtype=float32)"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Try to make a prediction using our model\n",
        "model.predict([17.0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xkK8QB8U8Uaa"
      },
      "source": [
        "## we got a prediction which is ~11 off --> exactly as much our mae gives at epoch 5"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3RHMm9c58fv7"
      },
      "source": [
        "## Improving our model \n",
        "\n",
        "We can improve the previous model by altering some of the steps we took to create a model:\n",
        "\n",
        "**1. Creating a model** - we might increase the number of hidden units (aka neurons) within each hidden layers, change the activation function of each leayer.\n",
        "\n",
        "**2. Compiling the model** - we might change the optimiation function or perhaps the **learning rate** of the optimization function.\n",
        "\n",
        "**3. Fitting the model** - fit a model with more epochs or with more data.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L9pAs9xm80Cl",
        "outputId": "18e7ccdc-5d7e-46bf-a051-6538ddedb967"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "1/1 [==============================] - 1s 857ms/step - loss: 11.2219 - mae: 11.2219\n",
            "Epoch 2/100\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 11.0894 - mae: 11.0894\n",
            "Epoch 3/100\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 10.9569 - mae: 10.9569\n",
            "Epoch 4/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 10.8244 - mae: 10.8244\n",
            "Epoch 5/100\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 10.6919 - mae: 10.6919\n",
            "Epoch 6/100\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 10.5594 - mae: 10.5594\n",
            "Epoch 7/100\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 10.4269 - mae: 10.4269\n",
            "Epoch 8/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 10.2944 - mae: 10.2944\n",
            "Epoch 9/100\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 10.1619 - mae: 10.1619\n",
            "Epoch 10/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 10.0294 - mae: 10.0294\n",
            "Epoch 11/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 9.8969 - mae: 9.8969\n",
            "Epoch 12/100\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 9.7644 - mae: 9.7644\n",
            "Epoch 13/100\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 9.6319 - mae: 9.6319\n",
            "Epoch 14/100\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 9.4994 - mae: 9.4994\n",
            "Epoch 15/100\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 9.3669 - mae: 9.3669\n",
            "Epoch 16/100\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 9.2344 - mae: 9.2344\n",
            "Epoch 17/100\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 9.1019 - mae: 9.1019\n",
            "Epoch 18/100\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 8.9694 - mae: 8.9694\n",
            "Epoch 19/100\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 8.8369 - mae: 8.8369\n",
            "Epoch 20/100\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 8.7044 - mae: 8.7044\n",
            "Epoch 21/100\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 8.5719 - mae: 8.5719\n",
            "Epoch 22/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 8.4394 - mae: 8.4394\n",
            "Epoch 23/100\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 8.3069 - mae: 8.3069\n",
            "Epoch 24/100\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 8.1744 - mae: 8.1744\n",
            "Epoch 25/100\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 8.0419 - mae: 8.0419\n",
            "Epoch 26/100\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 7.9094 - mae: 7.9094\n",
            "Epoch 27/100\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 7.7769 - mae: 7.7769\n",
            "Epoch 28/100\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 7.6444 - mae: 7.6444\n",
            "Epoch 29/100\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 7.5119 - mae: 7.5119\n",
            "Epoch 30/100\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 7.3794 - mae: 7.3794\n",
            "Epoch 31/100\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 7.2750 - mae: 7.2750\n",
            "Epoch 32/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 7.2694 - mae: 7.2694\n",
            "Epoch 33/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 7.2638 - mae: 7.2638\n",
            "Epoch 34/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 7.2581 - mae: 7.2581\n",
            "Epoch 35/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 7.2525 - mae: 7.2525\n",
            "Epoch 36/100\n",
            "1/1 [==============================] - 0s 56ms/step - loss: 7.2469 - mae: 7.2469\n",
            "Epoch 37/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 7.2412 - mae: 7.2412\n",
            "Epoch 38/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 7.2356 - mae: 7.2356\n",
            "Epoch 39/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 7.2300 - mae: 7.2300\n",
            "Epoch 40/100\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 7.2244 - mae: 7.2244\n",
            "Epoch 41/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 7.2188 - mae: 7.2188\n",
            "Epoch 42/100\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 7.2131 - mae: 7.2131\n",
            "Epoch 43/100\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 7.2075 - mae: 7.2075\n",
            "Epoch 44/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 7.2019 - mae: 7.2019\n",
            "Epoch 45/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 7.1962 - mae: 7.1962\n",
            "Epoch 46/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 7.1906 - mae: 7.1906\n",
            "Epoch 47/100\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 7.1850 - mae: 7.1850\n",
            "Epoch 48/100\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 7.1794 - mae: 7.1794\n",
            "Epoch 49/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 7.1737 - mae: 7.1737\n",
            "Epoch 50/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 7.1681 - mae: 7.1681\n",
            "Epoch 51/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 7.1625 - mae: 7.1625\n",
            "Epoch 52/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 7.1569 - mae: 7.1569\n",
            "Epoch 53/100\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 7.1512 - mae: 7.1512\n",
            "Epoch 54/100\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 7.1456 - mae: 7.1456\n",
            "Epoch 55/100\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 7.1400 - mae: 7.1400\n",
            "Epoch 56/100\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 7.1344 - mae: 7.1344\n",
            "Epoch 57/100\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 7.1287 - mae: 7.1287\n",
            "Epoch 58/100\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 7.1231 - mae: 7.1231\n",
            "Epoch 59/100\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 7.1175 - mae: 7.1175\n",
            "Epoch 60/100\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 7.1119 - mae: 7.1119\n",
            "Epoch 61/100\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 7.1062 - mae: 7.1062\n",
            "Epoch 62/100\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 7.1006 - mae: 7.1006\n",
            "Epoch 63/100\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 7.0950 - mae: 7.0950\n",
            "Epoch 64/100\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 7.0894 - mae: 7.0894\n",
            "Epoch 65/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 7.0838 - mae: 7.0838\n",
            "Epoch 66/100\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 7.0781 - mae: 7.0781\n",
            "Epoch 67/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 7.0725 - mae: 7.0725\n",
            "Epoch 68/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 7.0669 - mae: 7.0669\n",
            "Epoch 69/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 7.0613 - mae: 7.0613\n",
            "Epoch 70/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 7.0556 - mae: 7.0556\n",
            "Epoch 71/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 7.0500 - mae: 7.0500\n",
            "Epoch 72/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 7.0444 - mae: 7.0444\n",
            "Epoch 73/100\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 7.0388 - mae: 7.0388\n",
            "Epoch 74/100\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 7.0331 - mae: 7.0331\n",
            "Epoch 75/100\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 7.0275 - mae: 7.0275\n",
            "Epoch 76/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 7.0219 - mae: 7.0219\n",
            "Epoch 77/100\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 7.0163 - mae: 7.0163\n",
            "Epoch 78/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 7.0106 - mae: 7.0106\n",
            "Epoch 79/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 7.0050 - mae: 7.0050\n",
            "Epoch 80/100\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 6.9994 - mae: 6.9994\n",
            "Epoch 81/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 6.9938 - mae: 6.9938\n",
            "Epoch 82/100\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 6.9881 - mae: 6.9881\n",
            "Epoch 83/100\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 6.9825 - mae: 6.9825\n",
            "Epoch 84/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 6.9769 - mae: 6.9769\n",
            "Epoch 85/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 6.9713 - mae: 6.9713\n",
            "Epoch 86/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 6.9656 - mae: 6.9656\n",
            "Epoch 87/100\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 6.9600 - mae: 6.9600\n",
            "Epoch 88/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 6.9544 - mae: 6.9544\n",
            "Epoch 89/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 6.9488 - mae: 6.9488\n",
            "Epoch 90/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 6.9431 - mae: 6.9431\n",
            "Epoch 91/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 6.9375 - mae: 6.9375\n",
            "Epoch 92/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 6.9319 - mae: 6.9319\n",
            "Epoch 93/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 6.9263 - mae: 6.9263\n",
            "Epoch 94/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 6.9206 - mae: 6.9206\n",
            "Epoch 95/100\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 6.9150 - mae: 6.9150\n",
            "Epoch 96/100\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 6.9094 - mae: 6.9094\n",
            "Epoch 97/100\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 6.9038 - mae: 6.9038\n",
            "Epoch 98/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 6.8981 - mae: 6.8981\n",
            "Epoch 99/100\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 6.8925 - mae: 6.8925\n",
            "Epoch 100/100\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 6.8869 - mae: 6.8869\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f2ee4cf79d0>"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Rebuid our model\n",
        "\n",
        "# 1.Create a  model using the Sequential API \n",
        "\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(1)\n",
        "    ])\n",
        "\n",
        "# 2. Compile the model \n",
        "model.compile(loss=tf.keras.losses.mae, #mae is short for mean absolute error\n",
        "              optimizer=tf.keras.optimizers.SGD(), #mae is short for sochastic medial descent\n",
        "              metrics=[\"mae\"]) # \"mae\" - same as writing the function tf.keras....\n",
        "\n",
        "# 3. Fit the model (it will train longer than the previous one)\n",
        "model.fit(tf.expand_dims(X, axis=-1), y, epochs=100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bhkFBjA_BO8V",
        "outputId": "c04e1c2f-8569-4917-fce1-b8fcb9963ecf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 0s 197ms/step\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "array([[29.739855]], dtype=float32)"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Predict new model: \n",
        "\n",
        "# Try to make a prediction using our model\n",
        "model.predict([17.0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Po8W5hM4BkX7"
      },
      "source": [
        "## Correct number should have been 27. We can see that it improved from a difference of ~11 (first model) to ~2 :D\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fGfon0PTCEix",
        "outputId": "69f2df1c-89af-4000-e80d-798b2e68b207"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "1/1 [==============================] - 1s 716ms/step - loss: 12.3193 - mae: 12.3193\n",
            "Epoch 2/100\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 11.7804 - mae: 11.7804\n",
            "Epoch 3/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 11.2324 - mae: 11.2324\n",
            "Epoch 4/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 10.6601 - mae: 10.6601\n",
            "Epoch 5/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 10.0632 - mae: 10.0632\n",
            "Epoch 6/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 9.4503 - mae: 9.4503\n",
            "Epoch 7/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 8.7991 - mae: 8.7991\n",
            "Epoch 8/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 8.1072 - mae: 8.1072\n",
            "Epoch 9/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 7.3691 - mae: 7.3691\n",
            "Epoch 10/100\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 6.5758 - mae: 6.5758\n",
            "Epoch 11/100\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 5.7205 - mae: 5.7205\n",
            "Epoch 12/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 4.7947 - mae: 4.7947\n",
            "Epoch 13/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 4.3581 - mae: 4.3581\n",
            "Epoch 14/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 4.3134 - mae: 4.3134\n",
            "Epoch 15/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 4.2550 - mae: 4.2550\n",
            "Epoch 16/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 4.2442 - mae: 4.2442\n",
            "Epoch 17/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 4.1520 - mae: 4.1520\n",
            "Epoch 18/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 4.1739 - mae: 4.1739\n",
            "Epoch 19/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 4.0681 - mae: 4.0681\n",
            "Epoch 20/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 4.0807 - mae: 4.0807\n",
            "Epoch 21/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 3.9954 - mae: 3.9954\n",
            "Epoch 22/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 3.9739 - mae: 3.9739\n",
            "Epoch 23/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 3.9208 - mae: 3.9208\n",
            "Epoch 24/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 3.9047 - mae: 3.9047\n",
            "Epoch 25/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 3.9267 - mae: 3.9267\n",
            "Epoch 26/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 3.8797 - mae: 3.8797\n",
            "Epoch 27/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 3.9341 - mae: 3.9341\n",
            "Epoch 28/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 3.8678 - mae: 3.8678\n",
            "Epoch 29/100\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 3.9274 - mae: 3.9274\n",
            "Epoch 30/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 3.8751 - mae: 3.8751\n",
            "Epoch 31/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 3.9080 - mae: 3.9080\n",
            "Epoch 32/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 3.8893 - mae: 3.8893\n",
            "Epoch 33/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 3.8834 - mae: 3.8834\n",
            "Epoch 34/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 3.8969 - mae: 3.8969\n",
            "Epoch 35/100\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 3.8581 - mae: 3.8581\n",
            "Epoch 36/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 3.9046 - mae: 3.9046\n",
            "Epoch 37/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 3.8386 - mae: 3.8386\n",
            "Epoch 38/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 3.9054 - mae: 3.9054\n",
            "Epoch 39/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 3.8482 - mae: 3.8482\n",
            "Epoch 40/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 3.8862 - mae: 3.8862\n",
            "Epoch 41/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 3.8605 - mae: 3.8605\n",
            "Epoch 42/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 3.8608 - mae: 3.8608\n",
            "Epoch 43/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 3.8683 - mae: 3.8683\n",
            "Epoch 44/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 3.8352 - mae: 3.8352\n",
            "Epoch 45/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 3.8762 - mae: 3.8762\n",
            "Epoch 46/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 3.8106 - mae: 3.8106\n",
            "Epoch 47/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 3.8821 - mae: 3.8821\n",
            "Epoch 48/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 3.8234 - mae: 3.8234\n",
            "Epoch 49/100\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 3.8626 - mae: 3.8626\n",
            "Epoch 50/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 3.8328 - mae: 3.8328\n",
            "Epoch 51/100\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 3.8369 - mae: 3.8369\n",
            "Epoch 52/100\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 3.8408 - mae: 3.8408\n",
            "Epoch 53/100\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 3.8111 - mae: 3.8111\n",
            "Epoch 54/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 3.8489 - mae: 3.8489\n",
            "Epoch 55/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 3.7850 - mae: 3.7850\n",
            "Epoch 56/100\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 3.8585 - mae: 3.8585\n",
            "Epoch 57/100\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 3.7982 - mae: 3.7982\n",
            "Epoch 58/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 3.8377 - mae: 3.8377\n",
            "Epoch 59/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 3.8062 - mae: 3.8062\n",
            "Epoch 60/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 3.8117 - mae: 3.8117\n",
            "Epoch 61/100\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 3.8144 - mae: 3.8144\n",
            "Epoch 62/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 3.7856 - mae: 3.7856\n",
            "Epoch 63/100\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 3.8227 - mae: 3.8227\n",
            "Epoch 64/100\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 3.7593 - mae: 3.7593\n",
            "Epoch 65/100\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 3.8352 - mae: 3.8352\n",
            "Epoch 66/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 3.7725 - mae: 3.7725\n",
            "Epoch 67/100\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 3.8115 - mae: 3.8115\n",
            "Epoch 68/100\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 3.7807 - mae: 3.7807\n",
            "Epoch 69/100\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 3.7853 - mae: 3.7853\n",
            "Epoch 70/100\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 3.7891 - mae: 3.7891\n",
            "Epoch 71/100\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 3.7588 - mae: 3.7588\n",
            "Epoch 72/100\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 3.7975 - mae: 3.7975\n",
            "Epoch 73/100\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 3.7337 - mae: 3.7337\n",
            "Epoch 74/100\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 3.8105 - mae: 3.8105\n",
            "Epoch 75/100\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 3.7478 - mae: 3.7478\n",
            "Epoch 76/100\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 3.7840 - mae: 3.7840\n",
            "Epoch 77/100\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 3.7563 - mae: 3.7563\n",
            "Epoch 78/100\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 3.7575 - mae: 3.7575\n",
            "Epoch 79/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 3.7648 - mae: 3.7648\n",
            "Epoch 80/100\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 3.7307 - mae: 3.7307\n",
            "Epoch 81/100\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 3.7735 - mae: 3.7735\n",
            "Epoch 82/100\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 3.7125 - mae: 3.7125\n",
            "Epoch 83/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 3.7820 - mae: 3.7820\n",
            "Epoch 84/100\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 3.7242 - mae: 3.7242\n",
            "Epoch 85/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 3.7552 - mae: 3.7552\n",
            "Epoch 86/100\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 3.7329 - mae: 3.7329\n",
            "Epoch 87/100\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 3.7284 - mae: 3.7284\n",
            "Epoch 88/100\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 3.7416 - mae: 3.7416\n",
            "Epoch 89/100\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 3.7013 - mae: 3.7013\n",
            "Epoch 90/100\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 3.7505 - mae: 3.7505\n",
            "Epoch 91/100\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 3.6921 - mae: 3.6921\n",
            "Epoch 92/100\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 3.7522 - mae: 3.7522\n",
            "Epoch 93/100\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 3.7016 - mae: 3.7016\n",
            "Epoch 94/100\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 3.7251 - mae: 3.7251\n",
            "Epoch 95/100\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 3.7105 - mae: 3.7105\n",
            "Epoch 96/100\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 3.6979 - mae: 3.6979\n",
            "Epoch 97/100\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 3.7194 - mae: 3.7194\n",
            "Epoch 98/100\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 3.6705 - mae: 3.6705\n",
            "Epoch 99/100\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 3.7299 - mae: 3.7299\n",
            "Epoch 100/100\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 3.6711 - mae: 3.6711\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f2ee64869d0>"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Model improved again (#3)\n",
        "\n",
        "# 1.Create a  model using the Sequential API (this time we add an extra layer with 100 hidden units)\n",
        "\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(100, activation=\"relu\"),\n",
        "    tf.keras.layers.Dense(1)\n",
        "    ])\n",
        "\n",
        "# 2. Compile the model \n",
        "model.compile(loss=\"mae\",\n",
        "              optimizer=tf.keras.optimizers.SGD(), \n",
        "              metrics=[\"mae\"]) \n",
        "\n",
        "# 3. Fit the model (it will train longer than the previous one)\n",
        "model.fit(tf.expand_dims(X, axis=-1), y, epochs=100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p-U84DaRCNl2",
        "outputId": "a4e1f644-bc39-4db8-afcb-cc0f514efbcf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 0s 176ms/step\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "array([[31.223137]], dtype=float32)"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Predict new model: \n",
        "\n",
        "# Try to make a prediction using our model\n",
        "model.predict([17.0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ltmI05G4DbCY"
      },
      "source": [
        "## Correct number should have been 27. We can see that there is a difference of ~4, and not of ~2, hiow much the other model had...thus this model is performing worse than the previous one, even though it has a smaller mae"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qFQiqqkLEyFC",
        "outputId": "3762c2c7-4de1-474f-aa6d-9864c06406de"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "1/1 [==============================] - 1s 1s/step - loss: 12.7339 - mae: 12.7339\n",
            "Epoch 2/100\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 11.9052 - mae: 11.9052\n",
            "Epoch 3/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 11.0712 - mae: 11.0712\n",
            "Epoch 4/100\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 10.2556 - mae: 10.2556\n",
            "Epoch 5/100\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 9.6071 - mae: 9.6071\n",
            "Epoch 6/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 8.9779 - mae: 8.9779\n",
            "Epoch 7/100\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 8.3324 - mae: 8.3324\n",
            "Epoch 8/100\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 7.6675 - mae: 7.6675\n",
            "Epoch 9/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 6.9773 - mae: 6.9773\n",
            "Epoch 10/100\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 6.2578 - mae: 6.2578\n",
            "Epoch 11/100\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 5.5048 - mae: 5.5048\n",
            "Epoch 12/100\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 4.7182 - mae: 4.7182\n",
            "Epoch 13/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 3.9977 - mae: 3.9977\n",
            "Epoch 14/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 3.7582 - mae: 3.7582\n",
            "Epoch 15/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 3.8989 - mae: 3.8989\n",
            "Epoch 16/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 4.0165 - mae: 4.0165\n",
            "Epoch 17/100\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 4.2808 - mae: 4.2808\n",
            "Epoch 18/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 4.4803 - mae: 4.4803\n",
            "Epoch 19/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 4.5805 - mae: 4.5805\n",
            "Epoch 20/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 4.5931 - mae: 4.5931\n",
            "Epoch 21/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 4.5326 - mae: 4.5326\n",
            "Epoch 22/100\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 4.4073 - mae: 4.4073\n",
            "Epoch 23/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 4.2272 - mae: 4.2272\n",
            "Epoch 24/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 4.0037 - mae: 4.0037\n",
            "Epoch 25/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 3.7757 - mae: 3.7757\n",
            "Epoch 26/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 3.6633 - mae: 3.6633\n",
            "Epoch 27/100\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 3.5512 - mae: 3.5512\n",
            "Epoch 28/100\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 3.4389 - mae: 3.4389\n",
            "Epoch 29/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 3.3275 - mae: 3.3275\n",
            "Epoch 30/100\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 3.3583 - mae: 3.3583\n",
            "Epoch 31/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 3.3569 - mae: 3.3569\n",
            "Epoch 32/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 3.3252 - mae: 3.3252\n",
            "Epoch 33/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 3.2848 - mae: 3.2848\n",
            "Epoch 34/100\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 3.2317 - mae: 3.2317\n",
            "Epoch 35/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 3.1251 - mae: 3.1251\n",
            "Epoch 36/100\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 3.0259 - mae: 3.0259\n",
            "Epoch 37/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 2.9742 - mae: 2.9742\n",
            "Epoch 38/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 2.9566 - mae: 2.9566\n",
            "Epoch 39/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 2.9194 - mae: 2.9194\n",
            "Epoch 40/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 2.8601 - mae: 2.8601\n",
            "Epoch 41/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 2.7829 - mae: 2.7829\n",
            "Epoch 42/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 2.6897 - mae: 2.6897\n",
            "Epoch 43/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 2.5785 - mae: 2.5785\n",
            "Epoch 44/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 2.4573 - mae: 2.4573\n",
            "Epoch 45/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 2.3350 - mae: 2.3350\n",
            "Epoch 46/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 2.2170 - mae: 2.2170\n",
            "Epoch 47/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 2.1181 - mae: 2.1181\n",
            "Epoch 48/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 2.0317 - mae: 2.0317\n",
            "Epoch 49/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.9329 - mae: 1.9329\n",
            "Epoch 50/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.8220 - mae: 1.8220\n",
            "Epoch 51/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 1.6936 - mae: 1.6936\n",
            "Epoch 52/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 1.5465 - mae: 1.5465\n",
            "Epoch 53/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 1.4338 - mae: 1.4338\n",
            "Epoch 54/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 1.2796 - mae: 1.2796\n",
            "Epoch 55/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 1.1364 - mae: 1.1364\n",
            "Epoch 56/100\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 1.0045 - mae: 1.0045\n",
            "Epoch 57/100\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.8414 - mae: 0.8414\n",
            "Epoch 58/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.6584 - mae: 0.6584\n",
            "Epoch 59/100\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.4793 - mae: 0.4793\n",
            "Epoch 60/100\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.3216 - mae: 0.3216\n",
            "Epoch 61/100\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.2821 - mae: 0.2821\n",
            "Epoch 62/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.2139 - mae: 0.2139\n",
            "Epoch 63/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.3067 - mae: 0.3067\n",
            "Epoch 64/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.4669 - mae: 0.4669\n",
            "Epoch 65/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.5318 - mae: 0.5318\n",
            "Epoch 66/100\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.4286 - mae: 0.4286\n",
            "Epoch 67/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.6082 - mae: 0.6082\n",
            "Epoch 68/100\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.4514 - mae: 0.4514\n",
            "Epoch 69/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.5475 - mae: 0.5475\n",
            "Epoch 70/100\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.4334 - mae: 0.4334\n",
            "Epoch 71/100\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.3996 - mae: 0.3996\n",
            "Epoch 72/100\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.4192 - mae: 0.4192\n",
            "Epoch 73/100\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.4045 - mae: 0.4045\n",
            "Epoch 74/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.4016 - mae: 0.4016\n",
            "Epoch 75/100\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.2396 - mae: 0.2396\n",
            "Epoch 76/100\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.3249 - mae: 0.3249\n",
            "Epoch 77/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.3173 - mae: 0.3173\n",
            "Epoch 78/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.2367 - mae: 0.2367\n",
            "Epoch 79/100\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.2889 - mae: 0.2889\n",
            "Epoch 80/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.2590 - mae: 0.2590\n",
            "Epoch 81/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.2732 - mae: 0.2732\n",
            "Epoch 82/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.3136 - mae: 0.3136\n",
            "Epoch 83/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.2944 - mae: 0.2944\n",
            "Epoch 84/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.2543 - mae: 0.2543\n",
            "Epoch 85/100\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.2342 - mae: 0.2342\n",
            "Epoch 86/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.1792 - mae: 0.1792\n",
            "Epoch 87/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.1477 - mae: 0.1477\n",
            "Epoch 88/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.1554 - mae: 0.1554\n",
            "Epoch 89/100\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.1632 - mae: 0.1632\n",
            "Epoch 90/100\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.1497 - mae: 0.1497\n",
            "Epoch 91/100\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.2270 - mae: 0.2270\n",
            "Epoch 92/100\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.1988 - mae: 0.1988\n",
            "Epoch 93/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.2866 - mae: 0.2866\n",
            "Epoch 94/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.2691 - mae: 0.2691\n",
            "Epoch 95/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.3802 - mae: 0.3802\n",
            "Epoch 96/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.3505 - mae: 0.3505\n",
            "Epoch 97/100\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.1934 - mae: 0.1934\n",
            "Epoch 98/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.4458 - mae: 0.4458\n",
            "Epoch 99/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.4780 - mae: 0.4780\n",
            "Epoch 100/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.2037 - mae: 0.2037\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f2ee5660dd0>"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Model improved again (#4)\n",
        "\n",
        "# 1.Create a  model using the Sequential API \n",
        "\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(100, activation=\"relu\"),\n",
        "    tf.keras.layers.Dense(1)\n",
        "    ])\n",
        "\n",
        "# 2. Compile the model (we change the optimizer to Adam optimization algorithm - a better SGD)\n",
        "model.compile(loss=\"mae\",\n",
        "              optimizer=tf.keras.optimizers.Adam(lr=0.01), \n",
        "              metrics=[\"mae\"]) \n",
        "\n",
        "# 3. Fit the model (it will train longer than the previous one)\n",
        "model.fit(tf.expand_dims(X, axis=-1), y, epochs=100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NPb8yHqiGiac",
        "outputId": "b1e79204-9f5d-445f-a183-94f84cd02487"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 0s 182ms/step\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "array([[26.43606]], dtype=float32)"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Predict new model: \n",
        "\n",
        "# Try to make a prediction using our model\n",
        "model.predict([17.0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-rEywvS1Gl9j"
      },
      "source": [
        "## Big Bizniss - We have a differnce of ~0.5 between prediction and real value :D "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_YisjtjdIRxM",
        "outputId": "125d5a4b-f4ee-46d3-b450-422a1471e4cf"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(<tf.Tensor: shape=(50,), dtype=int32, numpy=\n",
              " array([-100,  -96,  -92,  -88,  -84,  -80,  -76,  -72,  -68,  -64,  -60,\n",
              "         -56,  -52,  -48,  -44,  -40,  -36,  -32,  -28,  -24,  -20,  -16,\n",
              "         -12,   -8,   -4,    0,    4,    8,   12,   16,   20,   24,   28,\n",
              "          32,   36,   40,   44,   48,   52,   56,   60,   64,   68,   72,\n",
              "          76,   80,   84,   88,   92,   96], dtype=int32)>,\n",
              " 50,\n",
              " <tf.Tensor: shape=(50,), dtype=int32, numpy=\n",
              " array([-90, -86, -82, -78, -74, -70, -66, -62, -58, -54, -50, -46, -42,\n",
              "        -38, -34, -30, -26, -22, -18, -14, -10,  -6,  -2,   2,   6,  10,\n",
              "         14,  18,  22,  26,  30,  34,  38,  42,  46,  50,  54,  58,  62,\n",
              "         66,  70,  74,  78,  82,  86,  90,  94,  98, 102, 106], dtype=int32)>,\n",
              " 50)"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# The 3 sets:\n",
        "\n",
        "X = tf.range(-100, 100, 4)\n",
        "y = X + 10\n",
        "\n",
        "X, len(X), y, len(y)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cr8y4E2qIktO",
        "outputId": "61e4ff10-6291-4320-aea5-eb53722cbdad"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(40, 10, 40, 10)"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Training set (80%) and testing (20%)\n",
        "\n",
        "X_train = X[:40] # 80%\n",
        "X_test = X[40:] # 20% \n",
        "\n",
        "y_train = y[:40]\n",
        "y_test = y[40:]\n",
        "\n",
        "len(X_train), len(X_test), len(y_train), len(y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 428
        },
        "id": "mex6FTZHI_Tr",
        "outputId": "d9170090-6432-434a-e06d-ad93e44714ba"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 720x504 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Visualize the data\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(10, 7))\n",
        "\n",
        "# Plot training data in blue:\n",
        "\n",
        "plt.scatter(X_train, y_train, c=\"b\", label=\"Training Data\")\n",
        "\n",
        "# Plot test data in green:\n",
        "\n",
        "plt.scatter(X_test, y_test, c=\"g\", label=\"Testing Data\")\n",
        "\n",
        "# Show a legend:\n",
        "plt.legend();"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "_K9TxElgKU8-"
      },
      "outputs": [],
      "source": [
        "# Let's build a neural network for our data:\n",
        "\n",
        "# 1. create the model:\n",
        "model = tf.keras.Sequential ([\n",
        "    tf.keras.layers.Dense(1)\n",
        "])  # for each X value we have a coresponding y value thus the layer.Dense is 1 \n",
        "\n",
        "# 2. Compile the model:\n",
        "model.compile(loss=tf.keras.losses.mae,\n",
        "              optimizer=tf.keras.optimizers.SGD(),\n",
        "              metrics=[\"mae\"])\n",
        "# # 3. Fit the model --> only on the training data\n",
        "# model.fit(tf.expand_dims(X_train, axis=-1), y_train, epochs=100)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 321
        },
        "id": "XgJ3yTftMIJJ",
        "outputId": "c6dffe60-2a82-4c3d-b999-174b0733330d"
      },
      "outputs": [
        {
          "ename": "ValueError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-22-5f15418b3570>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36msummary\u001b[0;34m(self, line_length, positions, print_fn, expand_nested, show_trainable)\u001b[0m\n\u001b[1;32m   2868\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuilt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2869\u001b[0m       raise ValueError(\n\u001b[0;32m-> 2870\u001b[0;31m           \u001b[0;34m'This model has not yet been built. '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2871\u001b[0m           \u001b[0;34m'Build the model first by calling `build()` or by calling '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2872\u001b[0m           'the model on a batch of data.')\n",
            "\u001b[0;31mValueError\u001b[0m: This model has not yet been built. Build the model first by calling `build()` or by calling the model on a batch of data."
          ]
        }
      ],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6t8ZS1MhMNYU"
      },
      "outputs": [],
      "source": [
        "#  Let's create a model which builds automatically by defining the input_shape argument\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "# Create a model (same as above)\n",
        "\n",
        "model=tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(10, input_shape=[1], name=\"input_layer\"), # X[0], y[0] are scalar, so the shape is 1\n",
        "    tf.keras.layers.Dense(1, name=\"output_layer\"),\n",
        "], name=\"model_1\")\n",
        "\n",
        "# Compile\n",
        "\n",
        "model.compile(loss=\"mae\",\n",
        "              optimizer=tf.keras.optimizers.SGD(),\n",
        "              metrics=[\"mae\"])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fLKB-Iu8QSrY"
      },
      "outputs": [],
      "source": [
        " model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0_ye2W91RAKk"
      },
      "source": [
        "## Calling summary() on our model shows us the layers it contains, the output shape and the number of parameters.\n",
        "\n",
        "**Total params** - total number of parameters in the model.\n",
        "\n",
        "**Trainable parameters** - these are the parameters (patterns) the model can update as it trains.\n",
        "\n",
        "**Non-trainable parameters** - these parameters aren't updated during training (this is typical when you bring in the already learned patterns from other models during transfer learning)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MRl8olJwSmIZ"
      },
      "outputs": [],
      "source": [
        "# Let's fit the model to the training data:\n",
        "\n",
        "model.fit(tf.expand_dims(X_train, axis=-1), y_train, epochs=100, verbose=0) #verbose means prnt the number of epochs :D\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pfQjaS6sT3FL"
      },
      "outputs": [],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wHbLb3-eUCj7"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.utils import plot_model\n",
        "\n",
        "plot_model(model=model, show_shapes=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WjX_AdnAVqHj"
      },
      "source": [
        "## Visualizing the predictions\n",
        "Now we've got a trained model, let's visualize some predictions.\n",
        "\n",
        "To visualize predictions, it's always a good idea to plot them against the ground truth labels.\n",
        "\n",
        "Often you'll see this in the form of y_test vs. y_pred (ground truth vs. predictions).\n",
        "\n",
        "First, we'll make some predictions on the test data (X_test), remember the model has never seen the test data.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QGGb1_J0y_UC"
      },
      "outputs": [],
      "source": [
        "# Make predictions\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "y_pred"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MZ7MQHDOy_wy"
      },
      "outputs": [],
      "source": [
        " y_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ipfYDLmXzWX5"
      },
      "outputs": [],
      "source": [
        "# Plotting Function:\n",
        "\n",
        "def plot_predictions(train_data=X_train, \n",
        "                     train_labels=y_train, \n",
        "                     test_data=X_test, \n",
        "                     test_labels=y_test, \n",
        "                     predictions=y_pred):\n",
        "  \"\"\"\n",
        "  Plots training data, test data and compares predictions.\n",
        "  \"\"\"\n",
        "  plt.figure(figsize=(10, 7))\n",
        "  # Plot training data in blue\n",
        "  plt.scatter(train_data, train_labels, c=\"b\", label=\"Training data\")\n",
        "  # Plot test data in green\n",
        "  plt.scatter(test_data, test_labels, c=\"g\", label=\"Testing data\")\n",
        "  # Plot the predictions in red (predictions were made on the test data)\n",
        "  plt.scatter(test_data, predictions, c=\"r\", label=\"Predictions\")\n",
        "  # Show the legend\n",
        "  plt.legend();"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-nLLOnkR0Sgc"
      },
      "outputs": [],
      "source": [
        "plot_predictions(train_data=X_train,\n",
        "                 train_labels=y_train,\n",
        "                 test_data=X_test,\n",
        "                 test_labels=y_test,\n",
        "                 predictions=y_preds)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jo4fyCOa0X1E"
      },
      "source": [
        "## Evaluating predictions\n",
        "Alongisde visualizations, evaulation metrics are your alternative best option for evaluating your model.\n",
        "\n",
        "Depending on the problem you're working on, different models have different evaluation metrics.\n",
        "\n",
        "Two of the main metrics used for regression problems are:\n",
        "\n",
        "**Mean absolute error (MAE)** - the mean difference between each of the predictions.\n",
        "\n",
        "**Mean squared error (MSE)** - the squared mean difference between of the predictions (use if larger errors are more detrimental than smaller errors).\n",
        "The lower each of these values, the better.\n",
        "\n",
        "You can also use model.evaluate() which will return the loss of the model as well as any metrics setup during the compile step.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H47L7k281WIJ"
      },
      "outputs": [],
      "source": [
        "# Evaluate the model on the test set\n",
        "\n",
        "model.evaluate(X_test, y_test);"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iE-TYd4A1gST"
      },
      "outputs": [],
      "source": [
        "# Calculate the mean absolute error \n",
        "\n",
        "mae = tf.metrics.mean_absolute_error(y_true=y_test, \n",
        "                                     y_pred=y_preds)\n",
        "mae"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fzf5GFpm33Ej"
      },
      "outputs": [],
      "source": [
        "# Check the test label tensor values\n",
        "y_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YxHG-pnm34zz"
      },
      "outputs": [],
      "source": [
        "# Check the tensor shapes\n",
        "\n",
        "y_test.shape, y_pred.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R375DGI4367z"
      },
      "outputs": [],
      "source": [
        "# Shape before squeeze()\n",
        "y_pred.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k1sekCKK3-Qz"
      },
      "outputs": [],
      "source": [
        "# Shape after squeeze()\n",
        "y_pred.squeeze().shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oB5dAcTi3_lr"
      },
      "outputs": [],
      "source": [
        "# What do they look like?\n",
        "y_test, y_pred.squeeze()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k_sqrTSt4Bjc"
      },
      "outputs": [],
      "source": [
        "# Calcuate the MAE\n",
        "mae = tf.metrics.mean_absolute_error(y_true=y_test, \n",
        "                                     y_pred=y_pred.squeeze()) # use squeeze() to make same shape\n",
        "mae"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "coHBLV744EST"
      },
      "outputs": [],
      "source": [
        "# Calculate the MSE\n",
        "mse = tf.metrics.mean_squared_error(y_true=y_test,\n",
        "                                    y_pred=y_pred.squeeze())\n",
        "mse"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4CF2mQxl4L9D"
      },
      "outputs": [],
      "source": [
        "# Returns the same as tf.metrics.mean_absolute_error()\n",
        "tf.reduce_mean(tf.abs(y_test-y_pred.squeeze()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iKKY3MDm4Oar"
      },
      "outputs": [],
      "source": [
        "def mae(y_test, y_pred):\n",
        "  \"\"\"\n",
        "  Calculuates mean absolute error between y_test and y_preds.\n",
        "  \"\"\"\n",
        "  return tf.metrics.mean_absolute_error(y_test,\n",
        "                                        y_pred)\n",
        "  \n",
        "def mse(y_test, y_pred):\n",
        "  \"\"\"\n",
        "  Calculates mean squared error between y_test and y_preds.\n",
        "  \"\"\"\n",
        "  return tf.metrics.mean_squared_error(y_test,\n",
        "                                       y_pred)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-oH692iX4StM"
      },
      "source": [
        "## Running experiments to improve a model\n",
        "After seeing the evaluation metrics and the predictions your model makes, it's likely you'll want to improve it.\n",
        "\n",
        "Again, there are many different ways you can do this, but 3 of the main ones are:\n",
        "\n",
        "**Get more data** - get more examples for your model to train on (more opportunities to learn patterns).\n",
        "\n",
        "**Make your model larger (use a more complex model)** - this might come in the form of more layers or more hidden units in each layer.\n",
        "\n",
        "**Train for longer** - give your model more of a chance to find the patterns in the data.\n",
        "Since we created our dataset, we could easily make more data but this isn't always the case when you're working with real-world datasets.\n",
        "\n",
        "So let's take a look at how we can improve our model using 2 and 3.\n",
        "\n",
        "To do so, we'll build 3 models and compare their results:\n",
        "\n",
        "model_1 - same as original model, 1 layer, trained for 100 epochs.\n",
        "\n",
        "model_2 - 2 layers, trained for 100 epochs.\n",
        "\n",
        "model_3 - 2 layers, trained for 500 epochs.\n",
        "Build model_1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F-foDRQJ4hok"
      },
      "source": [
        "## Model_1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RI2puytL6Wlt"
      },
      "outputs": [],
      "source": [
        "# Set random seed\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "# Replicate original model\n",
        "model_1 = tf.keras.Sequential([\n",
        "  tf.keras.layers.Dense(1)\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model_1.compile(loss=tf.keras.losses.mae,\n",
        "                optimizer=tf.keras.optimizers.SGD(),\n",
        "                metrics=['mae'])\n",
        "\n",
        "# Fit the model\n",
        "model_1.fit(tf.expand_dims(X_train, axis=-1), y_train, epochs=100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kVXs1TYB6Yib"
      },
      "outputs": [],
      "source": [
        "# Make and plot predictions for model_1\n",
        "y_preds_1 = model_1.predict(X_test)\n",
        "plot_predictions(predictions=y_preds_1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c6xG5tDS6b-M"
      },
      "outputs": [],
      "source": [
        "# Calculate model_1 metrics\n",
        "mae_1 = mae(y_test, y_preds_1.squeeze()).numpy()\n",
        "mse_1 = mse(y_test, y_preds_1.squeeze()).numpy()\n",
        "mae_1, mse_1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7UujgYzN6eMw"
      },
      "source": [
        "## Model_2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1HZWvMHm6ioe"
      },
      "outputs": [],
      "source": [
        "# Set random seed\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "# Replicate model_1 and add an extra layer\n",
        "model_2 = tf.keras.Sequential([\n",
        "  tf.keras.layers.Dense(10),\n",
        "  tf.keras.layers.Dense(1) # add a second layer\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model_2.compile(loss=tf.keras.losses.mae,\n",
        "                optimizer=tf.keras.optimizers.SGD(),\n",
        "                metrics=['mae'])\n",
        "\n",
        "# Fit the model\n",
        "model_2.fit(tf.expand_dims(X_train, axis=-1), y_train, epochs=100, verbose=0) # set verbose to 0 for less output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w6xpRlAg6lZZ"
      },
      "outputs": [],
      "source": [
        "# Make and plot predictions for model_2\n",
        "y_preds_2 = model_2.predict(X_test)\n",
        "plot_predictions(predictions=y_preds_2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vK1hyewI6sFp"
      },
      "outputs": [],
      "source": [
        "# Calculate model_2 metrics\n",
        "mae_2 = mae(y_test, y_preds_2.squeeze()).numpy()\n",
        "mse_2 = mse(y_test, y_preds_2.squeeze()).numpy()\n",
        "mae_2, mse_2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ito5GZNi6u0J"
      },
      "source": [
        "## Model_3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hVPSDxPB9t8F"
      },
      "outputs": [],
      "source": [
        "# Set random seed\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "# Replicate model_2\n",
        "model_3 = tf.keras.Sequential([\n",
        "  tf.keras.layers.Dense(1),\n",
        "  tf.keras.layers.Dense(1)\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model_3.compile(loss=tf.keras.losses.mae,\n",
        "                optimizer=tf.keras.optimizers.SGD(),\n",
        "                metrics=['mae'])\n",
        "\n",
        "# Fit the model (this time for 500 epochs, not 100)\n",
        "model_3.fit(tf.expand_dims(X_train, axis=-1), y_train, epochs=500, verbose=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tcqxViTc9wZ0"
      },
      "outputs": [],
      "source": [
        "# Make and plot predictions for model_3\n",
        "y_preds_3 = model_3.predict(X_test)\n",
        "plot_predictions(predictions=y_preds_3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ERmNvYRC9yHV"
      },
      "outputs": [],
      "source": [
        "# Calculate model_3 metrics\n",
        "mae_3 = mae(y_test, y_preds_3.squeeze()).numpy()\n",
        "mse_3 = mse(y_test, y_preds_3.squeeze()).numpy()\n",
        "mae_3, mse_3"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DCl7ZOem90G8"
      },
      "source": [
        "## Comparing results\n",
        "Now we've got results for 3 similar but slightly different results, let's compare them."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JtIPVHo595hx"
      },
      "source": [
        "djd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XVtDxdkP-ImN"
      },
      "outputs": [],
      "source": [
        "model_results = [[\"model_1\", mae_1, mse_1],\n",
        "                 [\"model_2\", mae_2, mse_2],\n",
        "                 [\"model_3\", mae_3, mae_3]]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fGJfF9JSBE6O"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "all_results = pd.DataFrame(model_results, columns=[\"model\", \"mae\", \"mse\"])\n",
        "all_results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jVItRGgvBGXm"
      },
      "source": [
        "From our experiments, it looks like model_2 performed the best.\n",
        "\n",
        "And now, you might be thinking, \"wow, comparing models is tedious...\" and it definitely can be, we've only compared 3 models here.\n",
        "\n",
        "But this is part of what machine learning modelling is about, trying many different combinations of models and seeing which performs best.\n",
        "\n",
        "Each model you build is a small experiment.\n",
        "\n",
        "## Tracking your experiments\n",
        "\n",
        "One really good habit to get into is tracking your modelling experiments to see which perform better than others.\n",
        "\n",
        "We've done a simple version of this above (keeping the results in different variables)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6VMaIDt2BKcV"
      },
      "source": [
        "## Saving a model\n",
        "\n",
        "Once you've trained a model and found one which performs to your liking, you'll probably want to save it for use elsewhere (like a web application or mobile device).\n",
        "\n",
        "You can save a TensorFlow/Keras model using model.save().\n",
        "\n",
        "There are two ways to save a model in TensorFlow:\n",
        "\n",
        "The SavedModel format (default).\n",
        "The HDF5 format.\n",
        "The main difference between the two is the SavedModel is automatically able to save custom objects (such as special layers) without additional modifications when loading the model back in.\n",
        "\n",
        "Which one should you use?\n",
        "\n",
        "It depends on your situation but the SavedModel format will suffice most of the time.\n",
        "\n",
        "Both methods use the same method call.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mzER0IZwBYOv"
      },
      "outputs": [],
      "source": [
        "# Save a model using the SavedModel format\n",
        "model_2.save('best_model_SavedModel_format')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mgiURT0PBbg-"
      },
      "outputs": [],
      "source": [
        "# Check it out - outputs a protobuf binary file (.pb) as well as other files\n",
        "!ls best_model_SavedModel_format"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d8r6AIw5BctW"
      },
      "outputs": [],
      "source": [
        "# Save a model using the HDF5 format\n",
        "model_2.save(\"best_model_HDF5_format.h5\") # note the addition of '.h5' on the end"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Yu7EBUqOBeXu"
      },
      "outputs": [],
      "source": [
        "# Check it out\n",
        "!ls best_model_HDF5_format.h5"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JNfJ21SKBfun"
      },
      "source": [
        "## Loading a model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o1W7a2PRBr4C"
      },
      "outputs": [],
      "source": [
        "# Load a model from the SavedModel format\n",
        "loaded_saved_model = tf.keras.models.load_model(\"best_model_SavedModel_format\")\n",
        "loaded_saved_model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WDr4EoXyBsQg"
      },
      "outputs": [],
      "source": [
        "# Compare model_2 with the SavedModel version (should return True)\n",
        "model_2_preds = model_2.predict(X_test)\n",
        "saved_model_preds = loaded_saved_model.predict(X_test)\n",
        "mae(y_test, saved_model_preds.squeeze()).numpy() == mae(y_test, model_2_preds.squeeze()).numpy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hrxReKqmBvoz"
      },
      "outputs": [],
      "source": [
        "# Load a model from the HDF5 format\n",
        "loaded_h5_model = tf.keras.models.load_model(\"best_model_HDF5_format.h5\")\n",
        "loaded_h5_model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TLMBoqOoByoO"
      },
      "outputs": [],
      "source": [
        "# Compare model_2 with the loaded HDF5 version (should return True)\n",
        "h5_model_preds = loaded_h5_model.predict(X_test)\n",
        "mae(y_test, h5_model_preds.squeeze()).numpy() == mae(y_test, model_2_preds.squeeze()).numpy()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L2TPuMeuB0Zw"
      },
      "source": [
        "## Downloading a model (from Google Colab)\n",
        "Say you wanted to get your model from Google Colab to your local machine, you can do one of the following things:\n",
        "\n",
        "Right click on the file in the files pane and click 'download'.\n",
        "Use the code below."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aEEGD85rB54o"
      },
      "outputs": [],
      "source": [
        "# Download the model (or any file) from Google Colab\n",
        "from google.colab import files\n",
        "files.download(\"best_model_HDF5_format.h5\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WTabkqiVB6NI"
      },
      "source": [
        "## A larger example\n",
        "\n",
        "\n",
        "Let's step it up a notch and build a model for a more feature rich dataset.\n",
        "\n",
        "More specifically we're going to try predict the cost of medical insurance for individuals based on a number of different parameters such as, age, sex, bmi, children, smoking_status and residential_region.\n",
        "\n",
        "To do, we'll leverage the pubically available Medical Cost dataset available from Kaggle and hosted on GitHub."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6nNfbNOWDwsy"
      },
      "outputs": [],
      "source": [
        "# Import required libraries\n",
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9f2nInWiDy7-"
      },
      "outputs": [],
      "source": [
        "# Read in the insurance dataset\n",
        "insurance = pd.read_csv(\"https://raw.githubusercontent.com/stedy/Machine-Learning-with-R-datasets/master/insurance.csv\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I8VNJqv8D1Zv"
      },
      "outputs": [],
      "source": [
        "# Check out the insurance dataset\n",
        "insurance.head()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2c-WEj8KD3rK"
      },
      "source": [
        "We're going to have to turn the non-numerical columns into numbers (because a neural network can't handle non-numerical inputs).\n",
        "\n",
        "To do so, we'll use the get_dummies() method in pandas.\n",
        "\n",
        "It converts categorical variables (like the sex, smoker and region columns) into numerical variables using one-hot encoding."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EDDncGGHoihh"
      },
      "outputs": [],
      "source": [
        "# Turn all categories into numbers\n",
        "insurance_one_hot = pd.get_dummies(insurance)\n",
        "insurance_one_hot.head() # view the converted columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s_cpl0v2oi-R"
      },
      "outputs": [],
      "source": [
        "# Create X & y values\n",
        "X = insurance_one_hot.drop(\"charges\", axis=1)\n",
        "y = insurance_one_hot[\"charges\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jcwDvmIEolP4"
      },
      "outputs": [],
      "source": [
        "# View features\n",
        "X.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4xnBBscSomt4"
      },
      "outputs": [],
      "source": [
        "# Create training and test sets\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, \n",
        "                                                    y, \n",
        "                                                    test_size=0.2, \n",
        "                                                    random_state=42) # set random state for reproducible splits"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cNI2b6jeoqHS"
      },
      "outputs": [],
      "source": [
        "# Set random seed\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "# Create a new model (same as model_2)\n",
        "insurance_model = tf.keras.Sequential([\n",
        "  tf.keras.layers.Dense(1),\n",
        "  tf.keras.layers.Dense(1)\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "insurance_model.compile(loss=tf.keras.losses.mae,\n",
        "                        optimizer=tf.keras.optimizers.SGD(),\n",
        "                        metrics=['mae'])\n",
        "\n",
        "# Fit the model\n",
        "insurance_model.fit(X_train, y_train, epochs=100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 884
        },
        "id": "G4FjCZc0or4I",
        "outputId": "f24c0a2f-515b-4de1-9aed-7b3fddc10733"
      },
      "outputs": [
        {
          "ename": "ValueError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-23-cb95fe8b46a2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;31m# Fit the model and save the history (we can plot this)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minsurance_model_2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtf__train_function\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m     13\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m                     \u001b[0mdo_return\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m                     \u001b[0mretval_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep_function\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m                 \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m                     \u001b[0mdo_return\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 1051, in train_function  *\n        return step_function(self, iterator)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 1040, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 1030, in run_step  **\n        outputs = model.train_step(data)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 889, in train_step\n        y_pred = self(x, training=True)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\", line 67, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/input_spec.py\", line 228, in assert_input_compatibility\n        raise ValueError(f'Input {input_index} of layer \"{layer_name}\" '\n\n    ValueError: Exception encountered when calling layer \"sequential_5\" (type Sequential).\n    \n    Input 0 of layer \"dense_7\" is incompatible with the layer: expected min_ndim=2, found ndim=1. Full shape received: (None,)\n    \n    Call arguments received by layer \"sequential_5\" (type Sequential):\n      • inputs=tf.Tensor(shape=(None,), dtype=int32)\n      • training=True\n      • mask=None\n"
          ]
        }
      ],
      "source": [
        "# Set random seed\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "# Add an extra layer and increase number of units\n",
        "insurance_model_2 = tf.keras.Sequential([\n",
        "  tf.keras.layers.Dense(100), # 100 units\n",
        "  tf.keras.layers.Dense(10), # 10 units\n",
        "  tf.keras.layers.Dense(1) # 1 unit (important for output layer)\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "insurance_model_2.compile(loss=tf.keras.losses.mae,\n",
        "                          optimizer=tf.keras.optimizers.Adam(), # Adam works but SGD doesn't \n",
        "                          metrics=['mae'])\n",
        "\n",
        "# Fit the model and save the history (we can plot this)\n",
        "history = insurance_model_2.fit(X_train, y_train, epochs=100, verbose=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 866
        },
        "id": "5E9x0fyCouPY",
        "outputId": "c8127b32-b9c7-4377-a40c-bf58cc36dc54"
      },
      "outputs": [
        {
          "ename": "ValueError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-24-86c7c887a7de>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Evaluate our larger model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0minsurance_model_2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtf__test_function\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m     13\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m                     \u001b[0mdo_return\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m                     \u001b[0mretval_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep_function\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m                 \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m                     \u001b[0mdo_return\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 1557, in test_function  *\n        return step_function(self, iterator)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 1546, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 1535, in run_step  **\n        outputs = model.test_step(data)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 1499, in test_step\n        y_pred = self(x, training=False)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\", line 67, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/input_spec.py\", line 228, in assert_input_compatibility\n        raise ValueError(f'Input {input_index} of layer \"{layer_name}\" '\n\n    ValueError: Exception encountered when calling layer \"sequential_5\" (type Sequential).\n    \n    Input 0 of layer \"dense_7\" is incompatible with the layer: expected min_ndim=2, found ndim=1. Full shape received: (None,)\n    \n    Call arguments received by layer \"sequential_5\" (type Sequential):\n      • inputs=tf.Tensor(shape=(None,), dtype=int32)\n      • training=False\n      • mask=None\n"
          ]
        }
      ],
      "source": [
        "# Evaluate our larger model\n",
        "insurance_model_2.evaluate(X_test, y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 217
        },
        "id": "0RC5Dwcqov0Q",
        "outputId": "d681b891-e0b3-43a2-b9f1-17dea812f33f"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-25-d2161532c1b2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Plot history (also known as a loss curve)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mylabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"loss\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxlabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"epochs\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'pd' is not defined"
          ]
        }
      ],
      "source": [
        "# Plot history (also known as a loss curve)\n",
        "pd.DataFrame(history.history).plot()\n",
        "plt.ylabel(\"loss\")\n",
        "plt.xlabel(\"epochs\");"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NQKrT8N9ox7o"
      },
      "source": [
        "From this, it looks like our model's loss (and MAE) were both still decreasing (in our case, MAE and loss are the same, hence the lines in the plot overlap eachother).\n",
        "\n",
        "What this tells us is the loss might go down if we try training it for longer."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 866
        },
        "id": "edMvUmx4o0rZ",
        "outputId": "6898750f-b2f6-418b-b297-3b28056366b7"
      },
      "outputs": [
        {
          "ename": "ValueError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-26-c96a293e1dcf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Try training for a little longer (100 more epochs)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mhistory_2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minsurance_model_2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtf__train_function\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m     13\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m                     \u001b[0mdo_return\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m                     \u001b[0mretval_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep_function\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m                 \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m                     \u001b[0mdo_return\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 1051, in train_function  *\n        return step_function(self, iterator)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 1040, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 1030, in run_step  **\n        outputs = model.train_step(data)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 889, in train_step\n        y_pred = self(x, training=True)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\", line 67, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/input_spec.py\", line 228, in assert_input_compatibility\n        raise ValueError(f'Input {input_index} of layer \"{layer_name}\" '\n\n    ValueError: Exception encountered when calling layer \"sequential_5\" (type Sequential).\n    \n    Input 0 of layer \"dense_7\" is incompatible with the layer: expected min_ndim=2, found ndim=1. Full shape received: (None,)\n    \n    Call arguments received by layer \"sequential_5\" (type Sequential):\n      • inputs=tf.Tensor(shape=(None,), dtype=int32)\n      • training=True\n      • mask=None\n"
          ]
        }
      ],
      "source": [
        "# Try training for a little longer (100 more epochs)\n",
        "history_2 = insurance_model_2.fit(X_train, y_train, epochs=100, verbose=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 901
        },
        "id": "sTv1r9GJo2Vw",
        "outputId": "b3e085be-ab63-4656-ba83-9ed20b6fedf8"
      },
      "outputs": [
        {
          "ename": "ValueError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-27-a2dbb4576d71>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Evaluate the model trained for 200 total epochs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0minsurance_model_2_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minsurance_model_2_mae\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minsurance_model_2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0minsurance_model_2_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minsurance_model_2_mae\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtf__test_function\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m     13\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m                     \u001b[0mdo_return\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m                     \u001b[0mretval_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep_function\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m                 \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m                     \u001b[0mdo_return\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 1557, in test_function  *\n        return step_function(self, iterator)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 1546, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 1535, in run_step  **\n        outputs = model.test_step(data)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 1499, in test_step\n        y_pred = self(x, training=False)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\", line 67, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/input_spec.py\", line 228, in assert_input_compatibility\n        raise ValueError(f'Input {input_index} of layer \"{layer_name}\" '\n\n    ValueError: Exception encountered when calling layer \"sequential_5\" (type Sequential).\n    \n    Input 0 of layer \"dense_7\" is incompatible with the layer: expected min_ndim=2, found ndim=1. Full shape received: (None,)\n    \n    Call arguments received by layer \"sequential_5\" (type Sequential):\n      • inputs=tf.Tensor(shape=(None,), dtype=int32)\n      • training=False\n      • mask=None\n"
          ]
        }
      ],
      "source": [
        "# Evaluate the model trained for 200 total epochs\n",
        "insurance_model_2_loss, insurance_model_2_mae = insurance_model_2.evaluate(X_test, y_test)\n",
        "insurance_model_2_loss, insurance_model_2_mae"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "id": "0ZI57IR-o3xI",
        "outputId": "1350e5b6-2b81-4648-f1d0-0b761f767c92"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-28-141ddbc9a36f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Plot the model trained for 200 total epochs loss curves\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory_2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mylabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"loss\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxlabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"epochs\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m \u001b[0;31m# note: epochs will only show 100 since we overrid the history variable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'pd' is not defined"
          ]
        }
      ],
      "source": [
        "# Plot the model trained for 200 total epochs loss curves\n",
        "pd.DataFrame(history_2.history).plot()\n",
        "plt.ylabel(\"loss\")\n",
        "plt.xlabel(\"epochs\"); # note: epochs will only show 100 since we overrid the history variable"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k8qmO5TOo5Vg"
      },
      "source": [
        "Preprocessing data (normalization and standardization)\n",
        "A common practice when working with neural networks is to make sure all of the data you pass to them is in the range 0 to 1.\n",
        "\n",
        "This practice is called normalization (scaling all values from their original range to, e.g. between 0 and 100,000 to be between 0 and 1).\n",
        "\n",
        "There is another process call standardization which converts all of your data to unit variance and 0 mean.\n",
        "\n",
        "These two practices are often part of a preprocessing pipeline (a series of functions to prepare your data for use with neural networks).\n",
        "\n",
        "Knowing this, some of the major steps you'll take to preprocess your data for a neural network include:\n",
        "\n",
        "Turning all of your data to numbers (a neural network can't handle strings).\n",
        "Making sure your data is in the right shape (verifying input and output shapes).\n",
        "Feature scaling:\n",
        "Normalizing data (making sure all values are between 0 and 1). This is done by subtracting the minimum value then dividing by the maximum value minus the minmum. This is also referred to as min-max scaling.\n",
        "Standardization (making sure all values have a mean of 0 and a variance of 1). This is done by substracting the mean value from the target feature and then dividing it by the standard deviation.\n",
        "Which one should you use?\n",
        "With neural networks you'll tend to favour normalization as they tend to prefer values between 0 and 1 (you'll see this espcially with image processing), however, you'll often find a neural network can perform pretty well with minimal feature scaling."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "yaPtAm-vo-Fp"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "\n",
        "# Read in the insurance dataset\n",
        "insurance = pd.read_csv(\"https://raw.githubusercontent.com/stedy/Machine-Learning-with-R-datasets/master/insurance.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "yQRUGb-FpH4B",
        "outputId": "626a588c-864b-4106-b5d9-b7bd9e7118cd"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-d7c591fb-8eeb-4fd6-aa28-d35fa66c527e\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>age</th>\n",
              "      <th>sex</th>\n",
              "      <th>bmi</th>\n",
              "      <th>children</th>\n",
              "      <th>smoker</th>\n",
              "      <th>region</th>\n",
              "      <th>charges</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>19</td>\n",
              "      <td>female</td>\n",
              "      <td>27.900</td>\n",
              "      <td>0</td>\n",
              "      <td>yes</td>\n",
              "      <td>southwest</td>\n",
              "      <td>16884.92400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>18</td>\n",
              "      <td>male</td>\n",
              "      <td>33.770</td>\n",
              "      <td>1</td>\n",
              "      <td>no</td>\n",
              "      <td>southeast</td>\n",
              "      <td>1725.55230</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>28</td>\n",
              "      <td>male</td>\n",
              "      <td>33.000</td>\n",
              "      <td>3</td>\n",
              "      <td>no</td>\n",
              "      <td>southeast</td>\n",
              "      <td>4449.46200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>33</td>\n",
              "      <td>male</td>\n",
              "      <td>22.705</td>\n",
              "      <td>0</td>\n",
              "      <td>no</td>\n",
              "      <td>northwest</td>\n",
              "      <td>21984.47061</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>32</td>\n",
              "      <td>male</td>\n",
              "      <td>28.880</td>\n",
              "      <td>0</td>\n",
              "      <td>no</td>\n",
              "      <td>northwest</td>\n",
              "      <td>3866.85520</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d7c591fb-8eeb-4fd6-aa28-d35fa66c527e')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-d7c591fb-8eeb-4fd6-aa28-d35fa66c527e button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-d7c591fb-8eeb-4fd6-aa28-d35fa66c527e');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "   age     sex     bmi  children smoker     region      charges\n",
              "0   19  female  27.900         0    yes  southwest  16884.92400\n",
              "1   18    male  33.770         1     no  southeast   1725.55230\n",
              "2   28    male  33.000         3     no  southeast   4449.46200\n",
              "3   33    male  22.705         0     no  northwest  21984.47061\n",
              "4   32    male  28.880         0     no  northwest   3866.85520"
            ]
          },
          "execution_count": 30,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Check out the data\n",
        "insurance.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BBVd-gwapJq4"
      },
      "source": [
        "Now, just as before, we need to transform the non-numerical columns into numbers and this time we'll also be normalizing the numerical columns with different ranges (to make sure they're all between 0 and 1).\n",
        "\n",
        "To do this, we're going to use a few classes from Scikit-Learn:\n",
        "\n",
        "make_column_transformer - build a multi-step data preprocessing function for the folllowing transformations:\n",
        "MinMaxScaler - make sure all numerical columns are normalized (between 0 and 1).\n",
        "OneHotEncoder - one hot encode the non-numerical columns."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        },
        "id": "jk8isvTwpN4i",
        "outputId": "46145f3c-fa7e-4a75-de79-2123c8d4adaa"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-32-699c52c66f58>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;31m# Build our train and test sets (use random state to ensure same split as before)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m42\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;31m# Fit column transformer on the training data only (doing so on test data would result in data leakage)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'train_test_split' is not defined"
          ]
        }
      ],
      "source": [
        "from sklearn.compose import make_column_transformer\n",
        "from sklearn.preprocessing import MinMaxScaler, OneHotEncoder\n",
        "\n",
        "# Create column transformer (this will help us normalize/preprocess our data)\n",
        "ct = make_column_transformer(\n",
        "    (MinMaxScaler(), [\"age\", \"bmi\", \"children\"]), # get all values between 0 and 1\n",
        "    (OneHotEncoder(handle_unknown=\"ignore\"), [\"sex\", \"smoker\", \"region\"])\n",
        ")\n",
        "\n",
        "# Create X & y\n",
        "X = insurance.drop(\"charges\", axis=1)\n",
        "y = insurance[\"charges\"]\n",
        "\n",
        "# Build our train and test sets (use random state to ensure same split as before)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Fit column transformer on the training data only (doing so on test data would result in data leakage)\n",
        "ct.fit(X_train)\n",
        "\n",
        "# Transform training and test data with normalization (MinMaxScalar) and one hot encoding (OneHotEncoder)\n",
        "X_train_normal = ct.transform(X_train)\n",
        "X_test_normal = ct.transform(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 321
        },
        "id": "N6X75dUQpOup",
        "outputId": "8adb2e80-dc6f-42ee-8ee6-548e1dd91c3c"
      },
      "outputs": [
        {
          "ename": "AttributeError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-33-87109d49a54e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Non-normalized and non-one-hot encoded data example\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mX_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    444\u001b[0m         \u001b[0mnp_config\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menable_numpy_behavior\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    445\u001b[0m       \"\"\")\n\u001b[0;32m--> 446\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    447\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    448\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'tensorflow.python.framework.ops.EagerTensor' object has no attribute 'loc'"
          ]
        }
      ],
      "source": [
        "# Non-normalized and non-one-hot encoded data example\n",
        "X_train.loc[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 183
        },
        "id": "NbddTEn5pTyg",
        "outputId": "7136d1f8-4393-4f66-bec9-86f9b33bd4c4"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-34-e091d162859d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Normalized and one-hot encoded example\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mX_train_normal\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'X_train_normal' is not defined"
          ]
        }
      ],
      "source": [
        "# Normalized and one-hot encoded example\n",
        "X_train_normal[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 200
        },
        "id": "ngn12n1wpU-p",
        "outputId": "38c9f05b-3785-41e0-b7c9-233c976dfcd2"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-35-8d9d3bba5307>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Notice the normalized/one-hot encoded shape is larger because of the extra columns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mX_train_normal\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'X_train_normal' is not defined"
          ]
        }
      ],
      "source": [
        "# Notice the normalized/one-hot encoded shape is larger because of the extra columns\n",
        "X_train_normal.shape, X_train.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 200
        },
        "id": "sx3xG5OgpWvR",
        "outputId": "ee86f98d-620b-43d8-b75f-c78d78b5858f"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-36-8e4ae72787cb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;31m# Fit the model for 200 epochs (same as insurance_model_2)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0minsurance_model_3\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_normal\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'X_train_normal' is not defined"
          ]
        }
      ],
      "source": [
        "# Set random seed\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "# Build the model (3 layers, 100, 10, 1 units)\n",
        "insurance_model_3 = tf.keras.Sequential([\n",
        "  tf.keras.layers.Dense(100),\n",
        "  tf.keras.layers.Dense(10),\n",
        "  tf.keras.layers.Dense(1)\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "insurance_model_3.compile(loss=tf.keras.losses.mae,\n",
        "                          optimizer=tf.keras.optimizers.Adam(),\n",
        "                          metrics=['mae'])\n",
        "\n",
        "# Fit the model for 200 epochs (same as insurance_model_2)\n",
        "insurance_model_3.fit(X_train_normal, y_train, epochs=200, verbose=0) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 200
        },
        "id": "3luYFA_WpYXx",
        "outputId": "c445556b-6050-4bfe-e134-81d698fe0246"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-37-248521f6428d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Evaulate 3rd model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0minsurance_model_3_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minsurance_model_3_mae\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minsurance_model_3\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test_normal\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'X_test_normal' is not defined"
          ]
        }
      ],
      "source": [
        "# Evaulate 3rd model\n",
        "insurance_model_3_loss, insurance_model_3_mae = insurance_model_3.evaluate(X_test_normal, y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 183
        },
        "id": "VsBbeua3padJ",
        "outputId": "f8a905d6-ccce-4a12-c670-6ed65a3d874b"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-38-53c3e0c6f8a5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Compare modelling results from non-normalized data and normalized data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0minsurance_model_2_mae\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minsurance_model_3_mae\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'insurance_model_2_mae' is not defined"
          ]
        }
      ],
      "source": [
        "# Compare modelling results from non-normalized data and normalized data\n",
        "insurance_model_2_mae, insurance_model_3_mae"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OCUccw0kpcdJ"
      },
      "source": [
        "From this we can see normalizing the data results in 10% less error using the same model than not normalizing the data.\n",
        "\n",
        "This is one of the main benefits of normalization: faster convergence time (a fancy way of saying, your model gets to better results faster).\n",
        "\n",
        "insurance_model_2 may have eventually achieved the same results as insurance_model_3 if we left it training for longer.\n",
        "\n",
        "Also, the results may change if we were to alter the architectures of the models, e.g. more hidden units per layer or more layers.\n",
        "\n",
        "But since our main goal as neural network practitioners is to decrease the time between experiments, anything that helps us get better results sooner is a plus."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OptXCiBIpeSJ"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.10.7 ('mltf')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.7"
    },
    "vscode": {
      "interpreter": {
        "hash": "ed146083bf8e3a7c608f08fc117d559069eec26672ac77c970ebd43102c2cd32"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
