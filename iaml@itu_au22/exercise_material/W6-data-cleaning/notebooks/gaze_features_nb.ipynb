{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "67d68d21",
   "metadata": {},
   "source": [
    "# <i class=\"fas fa-circle mandatory\"></i> Pupil detection\n",
    "<span class=\"badge badge-pill badge-danger\">mandatory</span><span class=\"badge badge-pill badge-dark\">notebook</span>\n",
    "\n",
    "This is the second part of the first assignment. You have to implement a method that detects the pupil in eye images. The ellipse is a suitable model for approximating the pupil shape as it is projected onto the two-dimensional image from three-dimensional space. Just as in the barcode exercise, you will use thresholding and BLOB detection to find pupil candidates. \n",
    "\n",
    "Additionally, you will implement the RANSAC method for making the pupil detection method more robust to outliers. Finally, you have to evaluate your implementations and reflect on the impact of using RANSAC as well as how much the pupil detection process is responsible for the final gaze error.\n",
    "\n",
    "```{note}\n",
    "The real notebook (the one in the materials repository or the one you can download from this page) contains a lot of extra utility code that has been hidden here for brevity. The code is fully commented and we recommend you read it whenever you are in doubt about what is happening.\n",
    "```\n",
    "\n",
    "## Hand-in\n",
    "You have to write your solutions and answers in this Jupyter Notebook and hand in the result together with the first part (exercise 5.3). You can find the assignment room on the LearnIT course page or by following this [link](https://learnit.itu.dk/mod/assign/view.php?id=155386). You can find more information on this website as well on the {doc}`../../../../info/about_exercises` page.\n",
    "\n",
    "## Tasks\n",
    "The following list is a summary of the tasks you need to complete to pass the exercise. Find the tasks in the exercise text with further instructions on what to do. \n",
    "\n",
    "<i class=\"fas fa-exclamation-circle mandatory\"></i> {ref}`basic:pupil` (**A-C**)\n",
    "\n",
    "<i class=\"fas fa-exclamation-circle mandatory\"></i> {ref}`ellipse:approx` (**A, B**)\n",
    "\n",
    "<i class=\"fas fa-exclamation-circle mandatory\"></i> {ref}`test:improve` (**A-D**)\n",
    "\n",
    "<i class=\"fas fa-exclamation-circle mandatory\"></i> {ref}`ransac` (**A-C**)\n",
    "\n",
    "<i class=\"fas fa-exclamation-circle mandatory\"></i> {ref}`evaluation:two` (**A-C**)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e383038",
   "metadata": {
    "tags": [
     "remove-cell"
    ]
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import json\n",
    "import cv2 as cv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from skimage.measure import EllipseModel\n",
    "\n",
    "from tqdm import tqdm\n",
    "from dataclasses import dataclass\n",
    "from typing import Tuple, NamedTuple, List\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import Ellipse\n",
    "import seaborn as sns\n",
    "\n",
    "from ipywidgets import interact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78055c38",
   "metadata": {
    "tags": [
     "remove-cell"
    ]
   },
   "outputs": [],
   "source": [
    "def load_json(folder, filename):\n",
    "    \"\"\"Load json file from subdirectory in \"inputs/images\" with the given filename\n",
    "    - without .json extension!\n",
    "\n",
    "    Returns: The json data as a dictionary or array (depending on the file).\n",
    "    \"\"\"\n",
    "    with open(os.path.join(os.path.abspath('../inputs/images/' + folder), f'{filename}.json')) as file:\n",
    "        data = json.load(file)\n",
    "        return data\n",
    "\n",
    "def create_pos_dataframe(data):\n",
    "    rows = [{'idx': idx, 'x': x, 'y': y} for idx, (x, y) in enumerate(data)]\n",
    "    df = pd.DataFrame.from_records(rows, index='idx')\n",
    "    return df\n",
    "\n",
    "def dist(a, b):\n",
    "    return np.linalg.norm(a - b)\n",
    "\n",
    "def center_crop(img, size):\n",
    "    width, height = size\n",
    "    i_height, i_width = img.shape[:2]\n",
    "\n",
    "    dy = (i_height-height)//2\n",
    "    dx = (i_width-width)//2\n",
    "\n",
    "    return img[dy: i_height-dy, dx: i_width-dx]\n",
    "\n",
    "def open_img(path, idx):\n",
    "    \"\"\"Open a single image from the provided path. The index specifies the image name.\"\"\"\n",
    "    img = cv.imread(path + f'/{idx}.jpg')\n",
    "    if img is None:\n",
    "        raise IOError(\"Could not read image\")\n",
    "    return img"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "431be9b1",
   "metadata": {},
   "source": [
    "## Data\n",
    "You will be working with the same dataset as last week but this time without the pre-calculated pupil positions. The cell below loads all the data necessary for the exercise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06872f76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enter dataset folder name here (any subfolder in inputs/images will do)\n",
    "dataset_folders = ['pattern0', 'pattern1', 'pattern2', 'moving_medium', 'moving_hard']\n",
    "\n",
    "# Load screen gaze positions\n",
    "positions = [create_pos_dataframe(load_json(f, 'positions')) for f in dataset_folders]\n",
    "# Load eye images\n",
    "images = [[open_img(os.path.abspath('../inputs/images/' + f), i) for i in range(len(p)-1)] for p, f in zip(positions, dataset_folders)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9118e62",
   "metadata": {},
   "source": [
    "## Gaze models\n",
    "To evaluate the pupil detector you need to include the gaze model implementation from last week. Just copy over your own implementation for the 2. degree polynomial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c152c336",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy paste your gaze code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74517bd5",
   "metadata": {
    "tags": []
   },
   "source": [
    "(basic:pupil)=\n",
    "## <i class=\"fas fa-exclamation-circle mandatory\"></i> Basic pupil detection\n",
    "\n",
    "The first step is to use preprocessing methods to generate and select pupil candidates using BLOB detection. Use the function stub `find_pupil_basic` for your implementation.  \n",
    "\n",
    "```{tip}\n",
    "Use whatever means you find necessary to test your solution as you develop it. The `images` list contains lists of images from each dataset. You may use these and evaluate the results directly. We also provide a helper function below (`plot_features`) that may help you with debugging issues with ellipse approximation.\n",
    "```\n",
    "\n",
    "**A): <i class=\"fas fa-code\"></i>** **Thresholding:** Create a binary image using the same procedure as in the previous exercise.\n",
    "\n",
    "**B): <i class=\"fas fa-code\"></i>** **Morphology:** Use morphological operators to remove noise from the resulting binary image.\n",
    "\n",
    "**C): <i class=\"fas fa-code\"></i>** **Pupil classification:** Find contours and use contour features to classify the BLOBS as either *pupil candidates* or not. *Hint: Using contour area is a good starting point. To avoid having multiple pupil candidates simply select the candidate with the largest area instead of using a threshold.*\n",
    "\n",
    "\n",
    "```{caution}\n",
    "You have to convert the contour points returned by OpenCV to floating point format. Otherwise, the behaviour of `EllipseModel` is unpredictable and will produce wrong results. You can use `a.astype(np.float64)` to convert array `a` to floating point.\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dce886f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_pupil_basic(img, threshold=50):\n",
    "    \"\"\"Detects and returns a single pupil candidate for a given image.\n",
    "\n",
    "    Returns: A pupil candidate (EllipseModel) and its contour points.\n",
    "    \"\"\"\n",
    "    # Write your implementation here.\n",
    "    model = EllipseModel()\n",
    "    contour = []\n",
    "    return model, contour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8deb4485",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_features(points, model_base=None, model_ransac=None):\n",
    "    \"\"\"This is a helper function for visualising the approximated pupil ellipses and original contour points.\n",
    "    If you just want to show a single model, simply leave the other model to the default (None)\n",
    "    \"\"\"\n",
    "    ax = plt.gca()\n",
    "    points = points.astype(np.float64)\n",
    "\n",
    "    plt.scatter(*points.T, label='Contour')\n",
    "    if model_base is not None:\n",
    "        plt.plot(*model_base.predict_xy(np.linspace(0, 2*np.pi)).T, label='Base')\n",
    "    if model_ransac is not None:\n",
    "        plt.plot(*model_ransac.predict_xy(np.linspace(0, 2*np.pi)).T, label='RANSAC')\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee2bb81f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ellipse fitting example\n",
    "iii = images[0][5]\n",
    "pb, b1 = find_pupil_basic(iii)\n",
    "# Uncomment when find_pupil_ransac is working.\n",
    "# plot_features(b1, pb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81efd2a5",
   "metadata": {},
   "source": [
    "(ellipse:approx)=\n",
    "## <i class=\"fas fa-exclamation-circle mandatory\"></i> Ellipse approximation\n",
    "The next step is to approximate the pupil with an ellipse. An ellipse can be described by the following quadratic function\n",
    "\n",
    "$$\n",
    "ax^2 + by^2 + cxy + dx + ey + f = 0,\n",
    "$$\n",
    "\n",
    "where a-f are the parameters. This function is linear in the parameters but it describes a conic section which does not need to be elliptical. The solutions are only elliptical when $b^2-4ac < 0$. This means that it is not possible to solve the equation using the simple least squares method. The solution involves the use of concepts from calculus which are outside the scope of this course. Therefore, we instead use a premade ellipse fitting model `EllipseModel` from the `scikit-image` python package.\n",
    "\n",
    "Make the following changes to the `find_pupil_basic` function:\n",
    "\n",
    "**A): <i class=\"fas fa-code\"></i>** **Create the model and estimate parameters:** Read the documentation for [EllipseModel](https://scikit-image.org/docs/0.9.x/api/skimage.measure.html#skimage.measure.EllipseModel). Then:\n",
    "- Instantiate an `EllipseModel` object.\n",
    "- Use the `.estimate` method to estimate the parameters for your chosen contour candidate.\n",
    "**B): <i class=\"fas fa-code\"></i>** **Return the model parameters:** Return the `.params` field which contains a list of the ellipse parameters.\n",
    "\n",
    "(test:improve)=\n",
    "## <i class=\"fas fa-exclamation-circle mandatory\"></i> Test and evaluation\n",
    "Below we provide code for detecting the pupil in each image in every dataset and for constructing training and testing datasets. You have to re-add the evaluation code from last weeks exercise. \n",
    "\n",
    "**A): <i class=\"fas fa-code\"></i>** **Copy evaluation code:** Copy your evaluation code for calculating the *root mean squared error* from part 1. We recommend you set up a function that returns the *rmse* for a specific dataset. This will make the general evaluation easier.\n",
    "\n",
    "**B): <i class=\"fas fa-code\"></i>** **Create barplot of rmse:** Visualise the *rmse* for each dataset by using a barplot.\n",
    "\n",
    "**C): <i class=\"fas fa-code\"></i>** **Write code for showing samples of detected pupil ellipses:** Implement a function for showing samples of detected pupils shown in the source images. The result should be similar to the visualisation from part 1 of the exercise (although it doesn't need to print every image).\n",
    "\n",
    "**D): <i class=\"fas fa-code\"></i>** **Evaluate:** Answer the following questions:\n",
    "- How well does the pupil detector work? Does it work equally well for all datasets and images?\n",
    "- Identify situations where the detector is less precise and describe their characteristics. \n",
    "- Make at least one improvement to the detector (or an attempt) and discuss the difference.\n",
    "- How do the gaze results compare to the pupil results? Describe the reason for any discrepancies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c853c992",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Base data\n",
    "positions_train = [df.iloc[:9] for df in positions]\n",
    "positions_test = [df.iloc[9:] for df in positions]\n",
    "images_train = [li[:9] for li in images]\n",
    "images_test = [li[9:] for li in images]\n",
    "\n",
    "# Uncomment the following lines when your find_pupil_basic function is working\n",
    "\n",
    "# Find pupils and construct dataframes\n",
    "# pupils_basic = [[find_pupil_basic(ii)[0].params for ii in images_row] for images_row in images]\n",
    "# pupils_basic = [pd.DataFrame(p, columns=['cx', 'cy', 'ax', 'ay', 'angle']) for p in pupils_basic]\n",
    "# Create train and test splits\n",
    "# pupils_basic_train = [df.iloc[:9] for df in pupils_basic]\n",
    "# pupils_basic_test = [df.iloc[9:] for df in pupils_basic]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1483e54b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your solution here."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f441734b",
   "metadata": {
    "tags": []
   },
   "source": [
    "(ransac)=\n",
    "## <i class=\"fas fa-exclamation-circle mandatory\"></i> RANSAC\n",
    "You now have a base implementation for detecting pupils. However, like with regular regression, the approximation method is sensitive to outliers. In this case, outliers may be spurious points caused by noise in the thresholding phase. Using RANSAC might improve the detection accuracy slightly by ignorring these outliers.\n",
    "\n",
    "You have to implement the function `ransac`. The function `find_pupil_ransac` should use the same method as the `find_pupil_basic` function with the exceptation that ellipse approximation is delegated to the `ransac` function. You are welcome to combine the pupil detection functions if you think that approach is easier.\n",
    "\n",
    "**A): <i class=\"fas fa-code\"></i>** **Implement RANSAC:** Use information from the course to implement the RANSAC algorithm. We provide a few hints:\n",
    "- You need to select a subset of `points`. The existing parameters suggest that each subset should consist of `len(points)*frac` points. You can use the following Numpy code to select a subset:\n",
    "    ```\n",
    "    subset_idx = np.random.choice(len(points), int(len(points)*frac), replace=False)\n",
    "    subset = points[subset_idx]\n",
    "    ```\n",
    "- Create a new `EllipseModel` for each iteration and estimate parameters like you did previously.\n",
    "- Use the `.residuals` method of the ellipse model to calculate the error of each contour point in `points`.\n",
    "- Count the number of points with an error less than `distance`.\n",
    "- Keep track of the best model, i.e. the one with most *inliers* (points below the error distance threshold).\n",
    "**B): <i class=\"fas fa-code\"></i>** **Finish `find_pupil_ransac`:** Complete the function and return the model parameters (a list of five values).\n",
    "\n",
    "**C): <i class=\"fas fa-code\"></i>** **Questions:** Answer the following:\n",
    "- Make a qualitative assessment of how the RANSAC approach compares to the simple approach. If you find a striking example, please discuss it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ca7d27f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ransac(points, frac=0.6, distance=0.5, iters=50):\n",
    "    # Write your implementation here.\n",
    "    return None, 0\n",
    "\n",
    "def find_pupil_ransac(img, threshold=50):\n",
    "    \"\"\"Detects and returns a single pupil candidate for a given image.\n",
    "\n",
    "    Returns: A pupil candidate in OpenCV ellipse format.\n",
    "    \"\"\"\n",
    "    # Write your implementation here.\n",
    "    model = EllipseModel()\n",
    "    contour = []\n",
    "    return model, contour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1c38909",
   "metadata": {},
   "outputs": [],
   "source": [
    "iii = images[0][5]\n",
    "pb, b1 = find_pupil_basic(iii)\n",
    "pr, b2 = find_pupil_ransac(iii)\n",
    "# Uncomment when find_pupil_ransac is working.\n",
    "# plot_features(b2, pb, pr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "903ef247",
   "metadata": {},
   "source": [
    "(evaluation:two)=\n",
    "## <i class=\"fas fa-exclamation-circle mandatory\"></i> Evaluation\n",
    "\n",
    "You now have to evaluate and compare the RANSAC and basic approach to pupil detection. We have included some code to generate pupil features using the RANSAC method for all datasets. The code is in the cell below this one. Just like for the basic version, we have created a training and test dataset for you to use in the gaze model.\n",
    "\n",
    "**A): <i class=\"fas fa-code\"></i>** **Calculate errors for RANSAC:** Calculate the *rmse* for each individual dataset when using the RANSAC ellipse approximation method. Calculate the errors for at least two different sets of parameters for the `ransac` function.\n",
    "\n",
    "**B): <i class=\"fas fa-code\"></i>** **Compare performance:** Visualise the errors of all approaches in the same plot and answer the following:\n",
    "- Does the RANSAC model improve performance and if yes, how significantly?\n",
    "- Explain any difference between the two RANSAC models. You should be able to explain how the parameters have impacted the outcome.\n",
    "\n",
    "**C): <i class=\"fas fa-code\"></i>** **Reflecting on the gaze error:** You will likely find that, even with RANSAC, the gaze error is still relatively high for the first three datasets and extremely high for the last two datasets. Answer the following:\n",
    "- What is the reason for this? You should be able to relate this to the concept of bias from the course. Consider the following thought experiment: What if the pupil detection method was perfect - what would the gaze error be? *Hint: The two datasets where the head is freely moving should reveal what our current model does not account for*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "443bd829",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment the following lines when your find_pupil_basic function is working\n",
    "\n",
    "# pupils_ransac = [[find_pupil_ransac(ii)[0].params for ii in images_row] for images_row in tqdm(images)]\n",
    "# pupils_ransac = [pd.DataFrame(p, columns=['cx', 'cy', 'ax', 'ay', 'angle']) for p in pupils_ransac]\n",
    "# pupils_ransac_train = [df.iloc[:9] for df in pupils_ransac]\n",
    "# pupils_ransac_test = [df.iloc[9:] for df in pupils_ransac]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad948c25",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gaze_error_ransac(idx):\n",
    "    # Your solution\n",
    "    return 0\n",
    "\n",
    "gaze_error_ransac(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37b4b19f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
