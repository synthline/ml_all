{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a92a0445",
   "metadata": {},
   "source": [
    "# <i class=\"fas fa-circle exercise\"></i> Preprocessing and cleaning\n",
    "<span class=\"badge badge-pill badge-warning\">exercise</span>\n",
    "<span class=\"badge badge-pill badge-dark\">notebook</span>\n",
    "\n",
    "The purpose of this exercise is to implement a procedure for extracting barcodes from images. This may be used as a pre-processing step for a barcode reader. You will work with binary images, BLOB detection, and BLOB classification.\n",
    "\n",
    "```{note}\n",
    "The real notebook (the one in the materials repository or the one you can download from this page) contains some extra utility code that has been hidden here for brevity. The code is fully commented and we recommend you read it whenever you are in doubt about what is happening.\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ab54081",
   "metadata": {
    "tags": [
     "remove-cell"
    ]
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2 as cv\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from glob import glob\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecff63c1",
   "metadata": {
    "tags": [
     "remove-cell"
    ]
   },
   "outputs": [],
   "source": [
    "def create_barcode_image(frame, M, size=(1280, 960)):\n",
    "    \"\"\"Transform frame such that the barcode lines appear parallel to either the horizontal or vertical axes.\n",
    "\n",
    "    Args:\n",
    "        frame: Input image to be transformed.\n",
    "        M: Homographic transformation.\n",
    "        size: Size of the resulting image. Defaults to (1280, 960).\n",
    "\n",
    "    Returns:\n",
    "        The transformed image.\n",
    "    \"\"\"\n",
    "    return np.zeros((size[1], size[0])) # Replace this when solving the exercise.\n",
    "\n",
    "def show_contours(preview, barcodes):\n",
    "    \"\"\"Draw contours in preview.\n",
    "\n",
    "    Args:\n",
    "        preview: Preview image (3 channels).\n",
    "        contours: Vector of vector of points.\n",
    "        contour_scores: Vector of floats.\n",
    "    \"\"\"\n",
    "    cv.polylines(preview, barcodes, True, (255, 0, 0), thickness=3)\n",
    "    plt.imshow(preview)\n",
    "\n",
    "\n",
    "def draw_barcode_preview(preview, barcode_img):\n",
    "    \"\"\"Draw the barcode as a small window in the corner of the preview image.\n",
    "\n",
    "    Args:\n",
    "        preview: Preview image (3 channels).\n",
    "        barcode_img: Barcode image (1 channel).\n",
    "    \"\"\"\n",
    "    b_small = cv.resize(barcode_img, (320, 240))\n",
    "    b_small = cv.cvtColor(b_small, cv.COLOR_GRAY2BGR)\n",
    "    cv.putText(\n",
    "        b_small, \"barcode img\", (10, 20), cv.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 255)\n",
    "    )\n",
    "\n",
    "    preview[:240, preview.shape[1] - 320 :, :] = b_small\n",
    "\n",
    "\n",
    "def draw_threshold_preview(preview, thresh_img):\n",
    "    \"\"\"Draw the threshold image as a small window in the corner of the preview image.\n",
    "\n",
    "    Args:\n",
    "        preview: Preview image (3 channels).\n",
    "        thresh_img: Threshold image (1 channel).\n",
    "    \"\"\"\n",
    "    t_small = cv.resize(thresh_img, (320, 240))\n",
    "    t_small = cv.cvtColor(t_small, cv.COLOR_GRAY2BGR)\n",
    "    cv.putText(\n",
    "        t_small, \"binary img\", (10, 20), cv.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 255)\n",
    "    )\n",
    "\n",
    "    preview[:240, :320, :] = t_small"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ec9c1c4",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Basic setup\n",
    "Our goal is to isolate the barcode and remove the perspective distortion caused by it not being parallel to the camera plane. This is done by using blob detection as explored during the lecture. The detected barcode is then transformed to remove the perspective distortion.\n",
    "\n",
    "This process can be broken down into the following steps:\n",
    "\n",
    "1. Use thresholding to form BLOBS around barcode boxes.\n",
    "2. Find contours in the resulting binary image.\n",
    "3. Evaluate each contour according to some metric.\n",
    "4. Select one or more contour candidates to process further.\n",
    "5. Try to approximate contour as a rectangle.\n",
    "6. Use rectangle corners to create a homography.\n",
    "7. Transform image such that barcode lines is rectified and the lines are vertical."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b6df271",
   "metadata": {},
   "source": [
    "## Data overview\n",
    "The following example loads a bunch of sample images for you to work with in the `images` list. Check out some of the other images by changing the list index.\n",
    "\n",
    "```{tip}\n",
    "Try out different images when implementing the exercise. You might want to find one of the easy or medium images for the initial version and then adapt it to work on the harder images. The `hardest1` image is there as an optional challenge if you want to make a more sophisicated solution - it doesn't work with our reference implementation.\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c87c94a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern = '../inputs/barcodes/*'\n",
    "paths = list(glob(pattern))\n",
    "\n",
    "# Load images and convert to RGB color space\n",
    "names = [os.path.basename(p) for p in paths]\n",
    "images = [cv.imread(path, cv.IMREAD_COLOR) for path in paths]\n",
    "images = [cv.cvtColor(img, cv.COLOR_BGR2RGB) for img in images]\n",
    "\n",
    "# Create gray-scale images for later\n",
    "gray = [cv.cvtColor(img, cv.COLOR_RGB2GRAY) for img in images]\n",
    "\n",
    "# Show example output\n",
    "idx = 4\n",
    "plt.imshow(images[idx])\n",
    "plt.title(names[idx].capitalize());"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bcf086a",
   "metadata": {},
   "source": [
    "## Image thresholding\n",
    "\n",
    "In order to find contours, we first have to create a binary image from which these can be found. Since our goal is to isolate the white barcode box, a regular binary threshold should suffice.\n",
    "\n",
    "- In the `image_threshold` function below, use [cv.threshold]() to create a binary image from the input `img`. Make sure you use `cv.THRESH_BINARY + cv.THRESH_OTSU` for the `type` parameter. This makes intensities above the threshold white in the output and uses _Otsu's_ method for determining this threshold. This also means that the `threshold` parameter will be ignorred.\n",
    "- Check the resulting output for different images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d98d12a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select image\n",
    "img = gray[idx]\n",
    "\n",
    "# Replace this with your implementation\n",
    "threshold = np.zeros(img.shape[:2], dtype=np.uint8) # Placeholder - replace when solving the exercise\n",
    "    \n",
    "# Show the result\n",
    "plt.imshow(threshold, cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de805617",
   "metadata": {},
   "source": [
    "### Morphology\n",
    "In the following steps you will use morphological operators to remove smaller artifacts caused by the threshold methods. You may consider this as data cleaning. Change the following in the code-cell above:\n",
    "\n",
    "- Create a kernel for the morphological operation using [cv.getStructuringElement](). Create an ellipse shape of size (5, 5).\n",
    "- Apply an open operation to the binary image using the kernel you just created using [cv.morphologyEx]().\n",
    "- Experiment with different kernel sizes, types, and add multiple different operations. Observe the changes to the preview image."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35c7e404",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Contour detection\n",
    "The barcode should now be reasonably well separated from the background. The next step is to use blob detection to find regions of connected pixels.\n",
    "\n",
    "- Find contours using [cv.findContours]() using `cv.RETR_LIST` and `cv.CHAIN_APPROX_NONE` for the `mode` and `method` parameters. Insert this into the `find_barcode` function after the `# (2)` comment and remove the placeholder contours variable. Note that two values are returned, the first of which are our contours."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d7b4d05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace this code\n",
    "contours, _ = ..., ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d02eee1",
   "metadata": {},
   "source": [
    "### BLOB features and classification\n",
    "The next step is to classify each BLOB as either a **barcode** or **not a barcode**. This can be done by computing and comparing BLOB features.\n",
    "\n",
    "A simple but suitable method is to assume that barcode BLOBs are rectangular. To determine \"rectangularedness\", we use two OpenCV functions. The first, [cv.contourArea(c)](https://docs.opencv.org/4.5.1/d3/dc0/group__imgproc__shape.html#ga2c759ed9f497d4a618048a2f56dc97f1) finds the actual pixel-area of a contour. The second, [cv.minAreaRect()](https://docs.opencv.org/4.5.1/d3/dc0/group__imgproc__shape.html#ga3d476a3417130ae5154aea421ca7ead9) fits a rotating rectangle to the contour. We then use the following formula to determine a ratio\n",
    "\n",
    "$$\n",
    "    r = \\frac{\\text{true contour area}}{\\text{rotated rectangle area}}.\n",
    "$$\n",
    "\n",
    "This number will always be between $0$ and $1$ because the rotated rectangle produced always encompasses all white pixels in the contour.\n",
    "\n",
    "- Implement the ratio calculation in the `contour_ratio` function.\n",
    "- Use `cv.minAreaRect` and `cv.contourArea` to calculate the ratio in the `contour_ratio` function and return the result.\n",
    "\n",
    "```{tip}\n",
    "The rectangle returned from `cv.minAreaRect` can be destructured as follows: `center, axes, angle = cv.minAreaRect(contour)`. This is not clear from the C++ docs.\n",
    "```\n",
    "\n",
    "This metric can be used to classify BLOBS as being either a barcode or not by testing the value against a threshold. Do the following:\n",
    "\n",
    "- Implement the classification in `classify_contours` function. Use the `threshold` argument to determine which contours are pupils.\n",
    "- Classify the image contours and save the result in a list.\n",
    "- Use the utility function `show_contours` (code shown in the cell below) to draw the possitively classified contours.\n",
    "\n",
    "\n",
    "```{note}\n",
    "This scoring function is similar to the loss functions you know from machine learning. As is the concept of classification.\n",
    "\n",
    "- Could you use machine learning for classifying BLOBS for this problem? \n",
    "- If yes, how would you set it up (don't think about the ML algorithm but what the data and labels would be).\n",
    "- If no, why not? How is this different from, e.g. classifying bird species?\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87c2ee30",
   "metadata": {},
   "outputs": [],
   "source": [
    "def contour_ratio(c):\n",
    "    \"\"\"Calculate the score of a given contour. Higher values are better.\n",
    "\n",
    "    Args:\n",
    "        c: Contour (list of points).\n",
    "        shape: (width, height) tuple.\n",
    "\n",
    "    Returns:\n",
    "        Score as a float value.\n",
    "    \"\"\"\n",
    "    return 0\n",
    "\n",
    "def classify_contours(contours, threshold):\n",
    "    # Your solution here\n",
    "    return []\n",
    "\n",
    "# Here we select the contour with the highest score.\n",
    "barcodes = classify_contours(contours, threshold=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45af3fec",
   "metadata": {},
   "outputs": [],
   "source": [
    "preview = images[idx].copy()\n",
    "show_contours(preview, barcodes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32fd1fb9",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Rectangle approximation and transformation\n",
    "\n",
    "The final step of preprocessing is to cut out the barcode from the image and transform it to a plain rectangular image which only contains the barcode. A barcode reader would then be able to read any code using the same base method.\n",
    "\n",
    "First, we approximate a four-sided polygon for the BLOB. The cell below already contains the implementation. Because the BLOB is may be distorted due to the effect of perspective, we can't use the `minAreaRect` function directly. Instead, to find the four corners, we use the function [cv.approxPolyDP](https://docs.opencv.org/3.4/d3/dc0/group__imgproc__shape.html#ga0012a5fdaea70b8a9970165d98722b4c) to approximate the BLOB shape as a polygon. By varying the precision parameter continuously, the method hopefully yields a four-sided polygon at some point. An exception is raised if this is not the case.\n",
    "\n",
    "- Check that the code below works and returns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b87e4394",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_contour_corners(c):\n",
    "    \"\"\"Approximate contour as a rectangle and extract the corner coordinates.\n",
    "\n",
    "    Args:\n",
    "        c: Contour.\n",
    "\n",
    "    Raises:\n",
    "        Exception: If a rectangle (four point approximation) could not be found.\n",
    "\n",
    "    Returns:\n",
    "        A list of four points.\n",
    "    \"\"\"\n",
    "    return np.zeros((4, 2)) # Replace this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ddec4be",
   "metadata": {},
   "outputs": [],
   "source": [
    "boxes = []\n",
    "for b in barcodes:\n",
    "    # Find corners\n",
    "    box = find_contour_corners(b)\n",
    "    boxes.append(box)\n",
    "\n",
    "    # Plot result\n",
    "    plt.scatter(*box.reshape(4, 2).T)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2ee4cfb",
   "metadata": {
    "tags": []
   },
   "source": [
    "Finally, we need to perform a perspective transformation. This is very similar to the affine transformation you made in an earlier exercise but uses four corresponding sets of points instead of three. This kind of transformation is called a *homography* and can transform between two planes under perspective distortion. This means we can map the flat barcode to a flat image where the barcode lines should be vertical.\n",
    "\n",
    "```{tip}\n",
    "Homographies are not part of the curriculum but they are extremely commonly used when working with images. \n",
    "```\n",
    "\n",
    "The code is once again provided for you below. The `get_homography` function body is similar to the code you wrote to infer an affine transformation earlier. The only difference is the addition of an extra pair of points and the use of the `findHomography` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c36134aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_homography(corners, size=(1280, 960)):\n",
    "    \"\"\"Calculate homography between corners and standardised flat image.\n",
    "\n",
    "    Args:\n",
    "        corners: Image corners.\n",
    "        size: Size of rectangle in result.\n",
    "\n",
    "    Returns:\n",
    "        Homography matrix.\n",
    "    \"\"\"\n",
    "    comp = np.array([[0, 0], [0, size[1]], [size[0], size[1]], [size[0], 0]])\n",
    "    M, _ = cv.findHomography(corners, comp)\n",
    "    return M\n",
    "    \n",
    "for box in boxes:\n",
    "    M = get_homography(box)\n",
    "    bc = create_barcode_image(images[idx], M)\n",
    "    plt.imshow(bc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa15391e",
   "metadata": {},
   "source": [
    "## Evaluation\n",
    "\n",
    "That should be it. Hopefully everything now just works! However, it is definitely more likely that something doesn't quite work yet or at least doesn't work ideally. Our own solution is not particularly robust, but it does work for certain books as long as you hold them at appropriate angles - it might be necessary to twist and turn them a bit.\n",
    "\n",
    "This is fine - the purpose of this exercise is to learn about binary images and BLOBS and give you some intuition for how to work with it. Therefore, we have also added some questions that are designed to let you think a bit deeper about the concepts used here. We encourage discussions and writing notes based on these.\n",
    "\n",
    "- List the most obvious areas of improvement for this applicaiton. You don't have to know the solution - just point to what the weak spots are and why. Using live capture (if possible) might make this easier to test.\n",
    "- Try to think of other BLOB features that might be useful for ranking barcode candidates.\n",
    "- Have you noticed that the homography doesn't always pick the right direction for the barcode? Why is this and what can be done about it?\n",
    "- If you haven't already, consider alternative approaches to this problem that still use some form of BLOB detection and processing."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
